14:44:58,777 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:45:11,843 root INFO 
id:en_de cur r: 0.1110 best r: 0.1110
14:45:24,898 root INFO 
id:en_zh cur r: 0.2690 best r: 0.2690
14:45:37,998 root INFO 
id:ro_en cur r: 0.5330 best r: 0.5330
14:45:51,112 root INFO 
id:et_en cur r: 0.4145 best r: 0.4145
14:46:04,241 root INFO 
id:si_en cur r: 0.2261 best r: 0.2261
14:46:30,480 root INFO 
id:ne_en cur r: 0.5366 best r: 0.5366
14:46:43,505 root INFO 
id:ru_en cur r: 0.4070 best r: 0.4070
14:46:43,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:48:14,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:48:14,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:48:14,963 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:48:14,968 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:48:14,973 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:48:14,978 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:48:14,984 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:48:28,73 root INFO Epoch 0 Global steps: 700 Train loss: 0.8141
en_de Dev loss: 0.8856 r:0.1149
en_zh Dev loss: 0.7681 r:0.2677
ro_en Dev loss: 0.6973 r:0.5698
et_en Dev loss: 0.5579 r:0.5245
si_en Dev loss: 0.7559 r:0.3991
ne_en Dev loss: 0.6174 r:0.5759
ru_en Dev loss: 0.6865 r:0.4951
Current avg r:0.4210 Best avg r: 0.4210
14:53:01,699 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:53:14,767 root INFO 
id:en_de cur r: 0.1221 best r: 0.1221
14:53:53,951 root INFO 
id:et_en cur r: 0.5615 best r: 0.5615
14:54:07,53 root INFO 
id:si_en cur r: 0.4183 best r: 0.4183
14:54:33,260 root INFO 
id:ne_en cur r: 0.5710 best r: 0.5710
14:54:46,259 root INFO 
id:ru_en cur r: 0.5330 best r: 0.5330
14:54:46,259 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:56:17,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
14:56:17,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
14:56:17,646 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
14:56:17,656 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
14:56:17,663 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
14:56:17,669 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
14:56:17,674 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
14:56:30,764 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8042
en_de Dev loss: 0.9244 r:0.1334
en_zh Dev loss: 0.7593 r:0.3135
ro_en Dev loss: 0.6903 r:0.5974
et_en Dev loss: 0.4955 r:0.5882
si_en Dev loss: 0.7428 r:0.4525
ne_en Dev loss: 0.5799 r:0.5695
ru_en Dev loss: 0.6647 r:0.6407
Current avg r:0.4707 Best avg r: 0.4707
15:01:03,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:01:17,44 root INFO 
id:en_de cur r: 0.1526 best r: 0.1526
15:01:30,98 root INFO 
id:en_zh cur r: 0.3445 best r: 0.3445
15:01:43,166 root INFO 
id:ro_en cur r: 0.6566 best r: 0.6566
15:01:56,249 root INFO 
id:et_en cur r: 0.6130 best r: 0.6130
15:02:09,345 root INFO 
id:si_en cur r: 0.4889 best r: 0.4889
15:02:35,539 root INFO 
id:ne_en cur r: 0.6723 best r: 0.6723
15:02:48,524 root INFO 
id:ru_en cur r: 0.6857 best r: 0.6857
15:02:48,525 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:04:19,950 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:04:19,957 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:04:19,962 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:04:19,967 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:04:19,974 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:04:19,980 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:04:19,985 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:04:33,96 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7058
en_de Dev loss: 0.9215 r:0.1600
en_zh Dev loss: 0.7450 r:0.3633
ro_en Dev loss: 0.6201 r:0.6731
et_en Dev loss: 0.4513 r:0.6379
si_en Dev loss: 0.7004 r:0.5227
ne_en Dev loss: 0.4580 r:0.6714
ru_en Dev loss: 0.5429 r:0.7129
Current avg r:0.5345 Best avg r: 0.5345
15:09:06,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:09:19,321 root INFO 
id:en_de cur r: 0.1530 best r: 0.1530
15:09:32,349 root INFO 
id:en_zh cur r: 0.3652 best r: 0.3652
15:09:45,420 root INFO 
id:ro_en cur r: 0.6929 best r: 0.6929
15:09:58,506 root INFO 
id:et_en cur r: 0.6480 best r: 0.6480
15:10:11,604 root INFO 
id:si_en cur r: 0.5189 best r: 0.5189
15:10:37,686 root INFO 
id:ru_en cur r: 0.7257 best r: 0.7257
15:10:37,686 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:12:09,62 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:12:09,70 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:12:09,74 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:12:09,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:12:09,85 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:12:09,90 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:12:09,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:12:22,192 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6954
en_de Dev loss: 0.9398 r:0.1621
en_zh Dev loss: 0.7429 r:0.3749
ro_en Dev loss: 0.5622 r:0.6965
et_en Dev loss: 0.4157 r:0.6598
si_en Dev loss: 0.6866 r:0.5314
ne_en Dev loss: 0.4716 r:0.6584
ru_en Dev loss: 0.5010 r:0.7371
Current avg r:0.5457 Best avg r: 0.5457
15:16:55,390 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:17:21,477 root INFO 
id:en_zh cur r: 0.3824 best r: 0.3824
15:17:34,538 root INFO 
id:ro_en cur r: 0.7118 best r: 0.7118
15:17:47,617 root INFO 
id:et_en cur r: 0.6697 best r: 0.6697
15:18:00,716 root INFO 
id:si_en cur r: 0.5311 best r: 0.5311
15:18:26,917 root INFO 
id:ne_en cur r: 0.6906 best r: 0.6906
15:18:39,900 root INFO 
id:ru_en cur r: 0.7292 best r: 0.7292
15:18:39,900 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:20:11,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:20:11,319 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:20:11,324 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:20:11,330 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:20:11,337 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:20:11,343 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:20:11,348 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:20:24,441 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6458
en_de Dev loss: 0.9528 r:0.1687
en_zh Dev loss: 0.7325 r:0.3959
ro_en Dev loss: 0.5446 r:0.7170
et_en Dev loss: 0.4079 r:0.6750
si_en Dev loss: 0.7197 r:0.5486
ne_en Dev loss: 0.4557 r:0.6816
ru_en Dev loss: 0.4756 r:0.7395
Current avg r:0.5609 Best avg r: 0.5609
15:24:57,515 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:25:10,574 root INFO 
id:en_de cur r: 0.1566 best r: 0.1566
15:25:23,616 root INFO 
id:en_zh cur r: 0.3842 best r: 0.3842
15:25:36,694 root INFO 
id:ro_en cur r: 0.7311 best r: 0.7311
15:25:49,777 root INFO 
id:et_en cur r: 0.6968 best r: 0.6968
15:26:02,877 root INFO 
id:si_en cur r: 0.5499 best r: 0.5499
15:26:29,76 root INFO 
id:ne_en cur r: 0.7126 best r: 0.7126
15:26:42,64 root INFO 
id:ru_en cur r: 0.7365 best r: 0.7365
15:26:42,65 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:28:13,459 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:28:13,467 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:28:13,471 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:28:13,476 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:28:13,483 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:28:13,488 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:28:13,493 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:28:26,588 root INFO Epoch 0 Global steps: 4200 Train loss: 0.6259
en_de Dev loss: 0.9472 r:0.1698
en_zh Dev loss: 0.7348 r:0.3965
ro_en Dev loss: 0.5088 r:0.7329
et_en Dev loss: 0.3949 r:0.6924
si_en Dev loss: 0.7077 r:0.5594
ne_en Dev loss: 0.4447 r:0.7093
ru_en Dev loss: 0.4448 r:0.7454
Current avg r:0.5722 Best avg r: 0.5722
15:32:59,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:33:25,807 root INFO 
id:en_zh cur r: 0.3909 best r: 0.3909
15:33:38,875 root INFO 
id:ro_en cur r: 0.7392 best r: 0.7392
15:34:31,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:36:02,506 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6080
en_de Dev loss: 0.9359 r:0.1654
en_zh Dev loss: 0.7232 r:0.4026
ro_en Dev loss: 0.4914 r:0.7435
et_en Dev loss: 0.4171 r:0.6869
si_en Dev loss: 0.7620 r:0.5531
ne_en Dev loss: 0.5583 r:0.6987
ru_en Dev loss: 0.4956 r:0.7362
Current avg r:0.5695 Best avg r: 0.5722
15:40:35,708 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:40:48,767 root INFO 
id:en_de cur r: 0.1667 best r: 0.1667
15:41:14,874 root INFO 
id:ro_en cur r: 0.7548 best r: 0.7548
15:42:07,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:43:38,516 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5672
en_de Dev loss: 0.9074 r:0.1758
en_zh Dev loss: 0.7108 r:0.3997
ro_en Dev loss: 0.4295 r:0.7616
et_en Dev loss: 0.3866 r:0.6849
si_en Dev loss: 0.6873 r:0.5606
ne_en Dev loss: 0.4808 r:0.6976
ru_en Dev loss: 0.4879 r:0.7239
Current avg r:0.5720 Best avg r: 0.5722
15:48:11,770 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:48:24,840 root INFO 
id:en_de cur r: 0.1957 best r: 0.1957
15:48:37,888 root INFO 
id:en_zh cur r: 0.4236 best r: 0.4236
15:48:50,959 root INFO 
id:ro_en cur r: 0.7707 best r: 0.7707
15:49:04,48 root INFO 
id:et_en cur r: 0.7008 best r: 0.7008
15:49:17,150 root INFO 
id:si_en cur r: 0.5810 best r: 0.5810
15:49:43,355 root INFO 
id:ne_en cur r: 0.7359 best r: 0.7359
15:49:56,343 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:51:27,788 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:51:27,796 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:51:27,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:51:27,805 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:51:27,811 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:51:27,817 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:51:27,821 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:51:40,925 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5698
en_de Dev loss: 0.8869 r:0.1958
en_zh Dev loss: 0.6799 r:0.4242
ro_en Dev loss: 0.3786 r:0.7739
et_en Dev loss: 0.3582 r:0.7024
si_en Dev loss: 0.6051 r:0.5918
ne_en Dev loss: 0.4003 r:0.7304
ru_en Dev loss: 0.4150 r:0.7439
Current avg r:0.5946 Best avg r: 0.5946
15:56:14,231 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:56:27,286 root INFO 
id:en_de cur r: 0.2059 best r: 0.2059
15:56:53,395 root INFO 
id:ro_en cur r: 0.7799 best r: 0.7799
15:57:19,574 root INFO 
id:si_en cur r: 0.5861 best r: 0.5861
15:57:45,655 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:59:17,57 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
15:59:17,63 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
15:59:17,68 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
15:59:17,73 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
15:59:17,79 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
15:59:17,84 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
15:59:17,89 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
15:59:30,197 root INFO Epoch 0 Global steps: 7000 Train loss: 0.6147
en_de Dev loss: 0.9240 r:0.2064
en_zh Dev loss: 0.7444 r:0.4200
ro_en Dev loss: 0.4370 r:0.7832
et_en Dev loss: 0.3888 r:0.7007
si_en Dev loss: 0.7723 r:0.5963
ne_en Dev loss: 0.4812 r:0.7245
ru_en Dev loss: 0.4682 r:0.7481
Current avg r:0.5970 Best avg r: 0.5970
16:04:04,145 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:04:17,231 root INFO 
id:en_de cur r: 0.2153 best r: 0.2153
16:04:43,360 root INFO 
id:ro_en cur r: 0.7934 best r: 0.7934
16:04:56,458 root INFO 
id:et_en cur r: 0.7053 best r: 0.7053
16:05:09,577 root INFO 
id:si_en cur r: 0.5863 best r: 0.5863
16:05:35,777 root INFO 
id:ne_en cur r: 0.7525 best r: 0.7525
16:05:48,767 root INFO 
id:ru_en cur r: 0.7579 best r: 0.7579
16:05:48,767 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:07:20,230 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:07:20,238 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:07:20,244 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:07:20,249 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:07:20,256 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:07:20,261 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:07:20,267 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:07:33,358 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5987
en_de Dev loss: 0.8936 r:0.2006
en_zh Dev loss: 0.6845 r:0.4225
ro_en Dev loss: 0.3634 r:0.7909
et_en Dev loss: 0.3494 r:0.7121
si_en Dev loss: 0.6164 r:0.5883
ne_en Dev loss: 0.3644 r:0.7438
ru_en Dev loss: 0.3542 r:0.7690
Current avg r:0.6039 Best avg r: 0.6039
16:12:06,769 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:13:38,206 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:15:09,663 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5622
en_de Dev loss: 0.9386 r:0.1971
en_zh Dev loss: 0.7694 r:0.4161
ro_en Dev loss: 0.4234 r:0.7895
et_en Dev loss: 0.3945 r:0.7045
si_en Dev loss: 0.7372 r:0.5841
ne_en Dev loss: 0.4805 r:0.7320
ru_en Dev loss: 0.4950 r:0.7396
Current avg r:0.5947 Best avg r: 0.6039
16:19:43,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:20:09,364 root INFO 
id:en_zh cur r: 0.4296 best r: 0.4296
16:20:22,431 root INFO 
id:ro_en cur r: 0.8042 best r: 0.8042
16:20:35,517 root INFO 
id:et_en cur r: 0.7085 best r: 0.7085
16:20:48,634 root INFO 
id:si_en cur r: 0.5956 best r: 0.5956
16:21:14,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:22:46,113 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:22:46,122 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:22:46,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:22:46,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:22:46,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:22:46,146 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:22:46,151 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:22:59,243 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5295
en_de Dev loss: 0.9212 r:0.1910
en_zh Dev loss: 0.6960 r:0.4322
ro_en Dev loss: 0.3559 r:0.8018
et_en Dev loss: 0.3615 r:0.7128
si_en Dev loss: 0.6684 r:0.5958
ne_en Dev loss: 0.4396 r:0.7462
ru_en Dev loss: 0.4227 r:0.7574
Current avg r:0.6053 Best avg r: 0.6053
16:27:32,976 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:27:46,50 root INFO 
id:en_de cur r: 0.2248 best r: 0.2248
16:27:59,115 root INFO 
id:en_zh cur r: 0.4376 best r: 0.4376
16:28:12,198 root INFO 
id:ro_en cur r: 0.8121 best r: 0.8121
16:28:25,295 root INFO 
id:et_en cur r: 0.7155 best r: 0.7155
16:28:38,400 root INFO 
id:si_en cur r: 0.6136 best r: 0.6136
16:29:04,591 root INFO 
id:ne_en cur r: 0.7637 best r: 0.7637
16:29:17,582 root INFO 
id:ru_en cur r: 0.7615 best r: 0.7615
16:29:17,582 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:30:48,999 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
16:30:49,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
16:30:49,11 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
16:30:49,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
16:30:49,23 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
16:30:49,28 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
16:30:49,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
16:31:02,128 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5433
en_de Dev loss: 0.8717 r:0.2097
en_zh Dev loss: 0.6743 r:0.4420
ro_en Dev loss: 0.3071 r:0.8128
et_en Dev loss: 0.3400 r:0.7205
si_en Dev loss: 0.5633 r:0.6155
ne_en Dev loss: 0.3453 r:0.7617
ru_en Dev loss: 0.3593 r:0.7715
Current avg r:0.6191 Best avg r: 0.6191
16:35:35,473 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:36:01,577 root INFO 
id:en_zh cur r: 0.4461 best r: 0.4461
16:37:06,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:38:38,324 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5395
en_de Dev loss: 0.8856 r:0.2120
en_zh Dev loss: 0.6933 r:0.4465
ro_en Dev loss: 0.3876 r:0.8093
et_en Dev loss: 0.3851 r:0.7118
si_en Dev loss: 0.6863 r:0.6043
ne_en Dev loss: 0.4117 r:0.7504
ru_en Dev loss: 0.4357 r:0.7531
Current avg r:0.6125 Best avg r: 0.6191
16:43:13,563 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:43:52,708 root INFO 
id:ro_en cur r: 0.8159 best r: 0.8159
16:44:05,805 root INFO 
id:et_en cur r: 0.7160 best r: 0.7160
16:44:44,992 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:46:16,485 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4868
en_de Dev loss: 0.8655 r:0.2179
en_zh Dev loss: 0.7015 r:0.4407
ro_en Dev loss: 0.3280 r:0.8160
et_en Dev loss: 0.3527 r:0.7192
si_en Dev loss: 0.7057 r:0.6014
ne_en Dev loss: 0.4089 r:0.7554
ru_en Dev loss: 0.4328 r:0.7548
Current avg r:0.6150 Best avg r: 0.6191
16:50:50,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:51:03,409 root INFO 
id:en_de cur r: 0.2276 best r: 0.2276
16:51:42,802 root INFO 
id:et_en cur r: 0.7166 best r: 0.7166
16:52:22,47 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:53:53,462 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4882
en_de Dev loss: 0.8690 r:0.2188
en_zh Dev loss: 0.7078 r:0.4362
ro_en Dev loss: 0.3358 r:0.8143
et_en Dev loss: 0.3507 r:0.7162
si_en Dev loss: 0.6613 r:0.5979
ne_en Dev loss: 0.3937 r:0.7532
ru_en Dev loss: 0.4091 r:0.7533
Current avg r:0.6128 Best avg r: 0.6191
16:58:24,832 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:58:37,789 root INFO 
id:en_de cur r: 0.2390 best r: 0.2390
16:58:50,723 root INFO 
id:en_zh cur r: 0.4530 best r: 0.4530
16:59:03,693 root INFO 
id:ro_en cur r: 0.8299 best r: 0.8299
16:59:16,666 root INFO 
id:et_en cur r: 0.7231 best r: 0.7231
16:59:29,646 root INFO 
id:si_en cur r: 0.6222 best r: 0.6222
16:59:55,625 root INFO 
id:ne_en cur r: 0.7702 best r: 0.7702
17:00:08,521 root INFO 
id:ru_en cur r: 0.7761 best r: 0.7761
17:00:08,522 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:01:39,95 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
17:01:39,105 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
17:01:39,112 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
17:01:39,120 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
17:01:39,127 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
17:01:39,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
17:01:39,141 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
17:01:52,124 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4899
en_de Dev loss: 0.8518 r:0.2200
en_zh Dev loss: 0.6570 r:0.4544
ro_en Dev loss: 0.2760 r:0.8270
et_en Dev loss: 0.3710 r:0.7244
si_en Dev loss: 0.5040 r:0.6237
ne_en Dev loss: 0.3316 r:0.7686
ru_en Dev loss: 0.3304 r:0.7777
Current avg r:0.6280 Best avg r: 0.6280
17:06:22,938 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:07:53,550 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:09:24,103 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4833
en_de Dev loss: 0.8935 r:0.2141
en_zh Dev loss: 0.7205 r:0.4492
ro_en Dev loss: 0.3835 r:0.8202
et_en Dev loss: 0.3945 r:0.7142
si_en Dev loss: 0.7958 r:0.6030
ne_en Dev loss: 0.5023 r:0.7525
ru_en Dev loss: 0.4574 r:0.7532
Current avg r:0.6152 Best avg r: 0.6280
17:13:54,815 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:14:20,685 root INFO 
id:en_zh cur r: 0.4539 best r: 0.4539
17:15:25,399 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:16:55,922 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4908
en_de Dev loss: 0.8776 r:0.2294
en_zh Dev loss: 0.7208 r:0.4516
ro_en Dev loss: 0.3556 r:0.8178
et_en Dev loss: 0.3736 r:0.7169
si_en Dev loss: 0.6763 r:0.6097
ne_en Dev loss: 0.4270 r:0.7557
ru_en Dev loss: 0.4743 r:0.7373
Current avg r:0.6169 Best avg r: 0.6280
17:21:26,622 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:21:52,476 root INFO 
id:en_zh cur r: 0.4755 best r: 0.4755
17:22:57,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:24:27,681 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5062
en_de Dev loss: 0.8766 r:0.1837
en_zh Dev loss: 0.6819 r:0.4700
ro_en Dev loss: 0.3628 r:0.8169
et_en Dev loss: 0.3807 r:0.7075
si_en Dev loss: 0.8030 r:0.6030
ne_en Dev loss: 0.4614 r:0.7567
ru_en Dev loss: 0.4367 r:0.7477
Current avg r:0.6122 Best avg r: 0.6280
17:28:58,431 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:30:28,982 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:31:59,526 root INFO Epoch 1 Global steps: 15400 Train loss: 0.4739
en_de Dev loss: 0.8793 r:0.1805
en_zh Dev loss: 0.6713 r:0.4594
ro_en Dev loss: 0.2967 r:0.8216
et_en Dev loss: 0.3572 r:0.7177
si_en Dev loss: 0.6469 r:0.6151
ne_en Dev loss: 0.3516 r:0.7620
ru_en Dev loss: 0.4039 r:0.7465
Current avg r:0.6147 Best avg r: 0.6280
17:36:30,257 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:38:00,832 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:39:31,393 root INFO Epoch 1 Global steps: 16100 Train loss: 0.5001
en_de Dev loss: 0.8956 r:0.1903
en_zh Dev loss: 0.7539 r:0.4513
ro_en Dev loss: 0.3252 r:0.8213
et_en Dev loss: 0.3684 r:0.7217
si_en Dev loss: 0.7236 r:0.6151
ne_en Dev loss: 0.3769 r:0.7649
ru_en Dev loss: 0.4401 r:0.7453
Current avg r:0.6157 Best avg r: 0.6280
17:44:02,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:45:32,904 root INFO 
id:ne_en cur r: 0.7714 best r: 0.7714
17:45:45,778 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:47:16,300 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4733
en_de Dev loss: 0.8795 r:0.1832
en_zh Dev loss: 0.6760 r:0.4666
ro_en Dev loss: 0.3097 r:0.8207
et_en Dev loss: 0.3590 r:0.7151
si_en Dev loss: 0.6847 r:0.6081
ne_en Dev loss: 0.3972 r:0.7632
ru_en Dev loss: 0.3947 r:0.7511
Current avg r:0.6154 Best avg r: 0.6280
17:51:46,998 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:53:17,529 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:54:48,51 root INFO Epoch 1 Global steps: 17500 Train loss: 0.5009
en_de Dev loss: 0.8977 r:0.1909
en_zh Dev loss: 0.6837 r:0.4736
ro_en Dev loss: 0.3294 r:0.8203
et_en Dev loss: 0.3757 r:0.7251
si_en Dev loss: 0.6201 r:0.6181
ne_en Dev loss: 0.3299 r:0.7704
ru_en Dev loss: 0.4065 r:0.7622
Current avg r:0.6229 Best avg r: 0.6280
17:59:18,729 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:00:49,287 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:02:19,794 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4820
en_de Dev loss: 0.8713 r:0.1700
en_zh Dev loss: 0.6684 r:0.4634
ro_en Dev loss: 0.2928 r:0.8174
et_en Dev loss: 0.3486 r:0.7164
si_en Dev loss: 0.6035 r:0.6134
ne_en Dev loss: 0.3455 r:0.7621
ru_en Dev loss: 0.4049 r:0.7413
Current avg r:0.6120 Best avg r: 0.6280
18:06:50,499 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:08:21,26 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:09:51,552 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4979
en_de Dev loss: 0.8597 r:0.1858
en_zh Dev loss: 0.6655 r:0.4640
ro_en Dev loss: 0.2977 r:0.8229
et_en Dev loss: 0.3527 r:0.7171
si_en Dev loss: 0.6221 r:0.6158
ne_en Dev loss: 0.4065 r:0.7664
ru_en Dev loss: 0.3913 r:0.7606
Current avg r:0.6189 Best avg r: 0.6280
18:14:22,313 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:14:48,187 root INFO 
id:en_zh cur r: 0.4780 best r: 0.4780
18:15:53,45 root INFO 
id:ne_en cur r: 0.7773 best r: 0.7773
18:16:05,927 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:17:36,533 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4515
en_de Dev loss: 0.8693 r:0.2100
en_zh Dev loss: 0.6829 r:0.4700
ro_en Dev loss: 0.3320 r:0.8208
et_en Dev loss: 0.3704 r:0.7217
si_en Dev loss: 0.6455 r:0.6204
ne_en Dev loss: 0.3630 r:0.7736
ru_en Dev loss: 0.3797 r:0.7760
Current avg r:0.6275 Best avg r: 0.6280
18:22:07,339 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:23:37,946 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:25:08,558 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4730
en_de Dev loss: 0.8563 r:0.2013
en_zh Dev loss: 0.6694 r:0.4642
ro_en Dev loss: 0.3049 r:0.8261
et_en Dev loss: 0.3504 r:0.7180
si_en Dev loss: 0.6314 r:0.6168
ne_en Dev loss: 0.3743 r:0.7690
ru_en Dev loss: 0.4071 r:0.7538
Current avg r:0.6213 Best avg r: 0.6280
18:29:39,275 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:30:05,125 root INFO 
id:en_zh cur r: 0.4881 best r: 0.4881
18:30:18,67 root INFO 
id:ro_en cur r: 0.8303 best r: 0.8303
18:31:09,908 root INFO 
id:ne_en cur r: 0.7802 best r: 0.7802
18:31:22,779 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:32:53,285 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_de.lang_agnost_mlp.dev.best.scores
18:32:53,292 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/en_zh.lang_agnost_mlp.dev.best.scores
18:32:53,297 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ro_en.lang_agnost_mlp.dev.best.scores
18:32:53,302 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/et_en.lang_agnost_mlp.dev.best.scores
18:32:53,308 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/si_en.lang_agnost_mlp.dev.best.scores
18:32:53,312 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ne_en.lang_agnost_mlp.dev.best.scores
18:32:53,318 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run0/ru_en.lang_agnost_mlp.dev.best.scores
18:33:06,278 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4608
en_de Dev loss: 0.8491 r:0.2237
en_zh Dev loss: 0.6530 r:0.4775
ro_en Dev loss: 0.2851 r:0.8281
et_en Dev loss: 0.3458 r:0.7232
si_en Dev loss: 0.6259 r:0.6174
ne_en Dev loss: 0.3268 r:0.7768
ru_en Dev loss: 0.3489 r:0.7801
Current avg r:0.6324 Best avg r: 0.6324
18:37:38,324 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:39:08,819 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:40:39,337 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4063
en_de Dev loss: 0.8486 r:0.2173
en_zh Dev loss: 0.6911 r:0.4610
ro_en Dev loss: 0.3262 r:0.8177
et_en Dev loss: 0.3780 r:0.7058
si_en Dev loss: 0.7208 r:0.6044
ne_en Dev loss: 0.3896 r:0.7610
ru_en Dev loss: 0.4294 r:0.7389
Current avg r:0.6152 Best avg r: 0.6324
18:45:10,63 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:46:40,581 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:48:11,78 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4341
en_de Dev loss: 0.8707 r:0.2019
en_zh Dev loss: 0.7402 r:0.4512
ro_en Dev loss: 0.3390 r:0.8211
et_en Dev loss: 0.3836 r:0.7033
si_en Dev loss: 0.7884 r:0.6069
ne_en Dev loss: 0.4147 r:0.7597
ru_en Dev loss: 0.4716 r:0.7282
Current avg r:0.6103 Best avg r: 0.6324
18:52:41,849 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:54:12,367 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:55:42,914 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4232
en_de Dev loss: 0.8529 r:0.2238
en_zh Dev loss: 0.6699 r:0.4751
ro_en Dev loss: 0.3126 r:0.8256
et_en Dev loss: 0.3677 r:0.7151
si_en Dev loss: 0.6604 r:0.6200
ne_en Dev loss: 0.3385 r:0.7683
ru_en Dev loss: 0.4117 r:0.7509
Current avg r:0.6255 Best avg r: 0.6324
19:00:13,693 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:01:44,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:03:14,722 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4273
en_de Dev loss: 0.8630 r:0.2084
en_zh Dev loss: 0.7207 r:0.4442
ro_en Dev loss: 0.3137 r:0.8193
et_en Dev loss: 0.3661 r:0.7062
si_en Dev loss: 0.6919 r:0.6048
ne_en Dev loss: 0.3821 r:0.7570
ru_en Dev loss: 0.4510 r:0.7215
Current avg r:0.6088 Best avg r: 0.6324
19:07:45,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:07:58,335 root INFO 
id:en_de cur r: 0.2391 best r: 0.2391
19:09:15,938 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:10:46,463 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4011
en_de Dev loss: 0.8600 r:0.2222
en_zh Dev loss: 0.7070 r:0.4534
ro_en Dev loss: 0.3124 r:0.8208
et_en Dev loss: 0.3688 r:0.7128
si_en Dev loss: 0.6973 r:0.6167
ne_en Dev loss: 0.3995 r:0.7610
ru_en Dev loss: 0.3963 r:0.7483
Current avg r:0.6193 Best avg r: 0.6324
19:15:17,215 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:16:47,815 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:18:18,350 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4207
en_de Dev loss: 0.8587 r:0.2192
en_zh Dev loss: 0.6847 r:0.4589
ro_en Dev loss: 0.3190 r:0.8231
et_en Dev loss: 0.3531 r:0.7199
si_en Dev loss: 0.7151 r:0.6188
ne_en Dev loss: 0.3891 r:0.7694
ru_en Dev loss: 0.4195 r:0.7464
Current avg r:0.6222 Best avg r: 0.6324
19:22:49,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:23:02,2 root INFO 
id:en_de cur r: 0.2507 best r: 0.2507
19:24:19,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:25:50,122 root INFO Epoch 2 Global steps: 25900 Train loss: 0.3918
en_de Dev loss: 0.8642 r:0.2212
en_zh Dev loss: 0.7468 r:0.4454
ro_en Dev loss: 0.3354 r:0.8189
et_en Dev loss: 0.3768 r:0.7077
si_en Dev loss: 0.7724 r:0.6052
ne_en Dev loss: 0.4413 r:0.7596
ru_en Dev loss: 0.5017 r:0.7042
Current avg r:0.6089 Best avg r: 0.6324
19:30:20,950 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:31:51,556 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:33:22,133 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4282
en_de Dev loss: 0.8677 r:0.2407
en_zh Dev loss: 0.7336 r:0.4595
ro_en Dev loss: 0.3507 r:0.8167
et_en Dev loss: 0.3922 r:0.7080
si_en Dev loss: 0.7088 r:0.6128
ne_en Dev loss: 0.4062 r:0.7640
ru_en Dev loss: 0.4716 r:0.7223
Current avg r:0.6177 Best avg r: 0.6324
19:37:52,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:39:23,536 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:40:54,94 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4371
en_de Dev loss: 0.8883 r:0.1826
en_zh Dev loss: 0.6759 r:0.4735
ro_en Dev loss: 0.2985 r:0.8241
et_en Dev loss: 0.3664 r:0.7121
si_en Dev loss: 0.5759 r:0.6170
ne_en Dev loss: 0.3432 r:0.7651
ru_en Dev loss: 0.4133 r:0.7357
Current avg r:0.6157 Best avg r: 0.6324
19:45:24,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:46:03,633 root INFO 
id:ro_en cur r: 0.8307 best r: 0.8307
19:46:55,383 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:48:25,923 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4233
en_de Dev loss: 0.8742 r:0.2032
en_zh Dev loss: 0.7016 r:0.4620
ro_en Dev loss: 0.2932 r:0.8279
et_en Dev loss: 0.3549 r:0.7134
si_en Dev loss: 0.6175 r:0.6163
ne_en Dev loss: 0.3762 r:0.7593
ru_en Dev loss: 0.4219 r:0.7408
Current avg r:0.6176 Best avg r: 0.6324
19:52:56,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:54:27,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:55:57,862 root INFO Epoch 2 Global steps: 28700 Train loss: 0.3964
en_de Dev loss: 0.8713 r:0.2111
en_zh Dev loss: 0.7281 r:0.4676
ro_en Dev loss: 0.3282 r:0.8208
et_en Dev loss: 0.3758 r:0.7120
si_en Dev loss: 0.7464 r:0.6067
ne_en Dev loss: 0.4118 r:0.7556
ru_en Dev loss: 0.4226 r:0.7495
Current avg r:0.6176 Best avg r: 0.6324
20:00:28,647 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:01:59,182 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:03:29,657 root INFO Epoch 2 Global steps: 29400 Train loss: 0.3915
en_de Dev loss: 0.8813 r:0.1937
en_zh Dev loss: 0.7648 r:0.4524
ro_en Dev loss: 0.3442 r:0.8168
et_en Dev loss: 0.3837 r:0.7037
si_en Dev loss: 0.7505 r:0.6070
ne_en Dev loss: 0.4246 r:0.7594
ru_en Dev loss: 0.4872 r:0.7097
Current avg r:0.6061 Best avg r: 0.6324
20:08:00,397 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:09:30,925 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:11:01,428 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4133
en_de Dev loss: 0.8499 r:0.2160
en_zh Dev loss: 0.7160 r:0.4450
ro_en Dev loss: 0.3070 r:0.8179
et_en Dev loss: 0.3646 r:0.7023
si_en Dev loss: 0.6768 r:0.5994
ne_en Dev loss: 0.4242 r:0.7500
ru_en Dev loss: 0.4418 r:0.7161
Current avg r:0.6067 Best avg r: 0.6324
20:15:32,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:16:10,940 root INFO 
id:ro_en cur r: 0.8329 best r: 0.8329
20:17:02,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:18:33,166 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4199
en_de Dev loss: 0.8689 r:0.2176
en_zh Dev loss: 0.7438 r:0.4591
ro_en Dev loss: 0.3159 r:0.8277
et_en Dev loss: 0.3793 r:0.7123
si_en Dev loss: 0.7266 r:0.6115
ne_en Dev loss: 0.3953 r:0.7654
ru_en Dev loss: 0.4938 r:0.7191
Current avg r:0.6161 Best avg r: 0.6324
20:23:03,916 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:24:34,505 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:26:05,48 root INFO Epoch 2 Global steps: 31500 Train loss: 0.4085
en_de Dev loss: 0.9013 r:0.2070
en_zh Dev loss: 0.8404 r:0.4275
ro_en Dev loss: 0.3565 r:0.8160
et_en Dev loss: 0.3827 r:0.6992
si_en Dev loss: 0.7983 r:0.5887
ne_en Dev loss: 0.5126 r:0.7561
ru_en Dev loss: 0.5511 r:0.6901
Current avg r:0.5978 Best avg r: 0.6324
20:30:37,334 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:32:07,908 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:33:38,478 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3553
en_de Dev loss: 0.8624 r:0.2302
en_zh Dev loss: 0.7338 r:0.4482
ro_en Dev loss: 0.3414 r:0.8146
et_en Dev loss: 0.3797 r:0.6987
si_en Dev loss: 0.7997 r:0.5827
ne_en Dev loss: 0.4952 r:0.7460
ru_en Dev loss: 0.4496 r:0.7230
Current avg r:0.6062 Best avg r: 0.6324
20:38:09,272 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:39:39,802 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:41:10,367 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3646
en_de Dev loss: 0.8724 r:0.2260
en_zh Dev loss: 0.7502 r:0.4503
ro_en Dev loss: 0.3399 r:0.8188
et_en Dev loss: 0.3901 r:0.7041
si_en Dev loss: 0.7556 r:0.5906
ne_en Dev loss: 0.4526 r:0.7552
ru_en Dev loss: 0.4805 r:0.7257
Current avg r:0.6101 Best avg r: 0.6324
20:45:41,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:47:11,696 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:48:42,277 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3421
en_de Dev loss: 0.8804 r:0.2159
en_zh Dev loss: 0.7644 r:0.4411
ro_en Dev loss: 0.3468 r:0.8174
et_en Dev loss: 0.3817 r:0.7008
si_en Dev loss: 0.7915 r:0.5852
ne_en Dev loss: 0.4889 r:0.7499
ru_en Dev loss: 0.4889 r:0.7214
Current avg r:0.6045 Best avg r: 0.6324
20:53:12,968 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:54:43,561 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:56:14,156 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3666
en_de Dev loss: 0.8641 r:0.2085
en_zh Dev loss: 0.7361 r:0.4437
ro_en Dev loss: 0.3232 r:0.8216
et_en Dev loss: 0.3975 r:0.6989
si_en Dev loss: 0.7079 r:0.5868
ne_en Dev loss: 0.3909 r:0.7544
ru_en Dev loss: 0.4544 r:0.7152
Current avg r:0.6042 Best avg r: 0.6324
21:00:44,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:02:15,284 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:03:45,718 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3599
en_de Dev loss: 0.8722 r:0.2133
en_zh Dev loss: 0.7437 r:0.4466
ro_en Dev loss: 0.3566 r:0.8207
et_en Dev loss: 0.3855 r:0.7036
si_en Dev loss: 0.7294 r:0.5907
ne_en Dev loss: 0.4173 r:0.7573
ru_en Dev loss: 0.4513 r:0.7331
Current avg r:0.6093 Best avg r: 0.6324
21:08:16,196 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:09:46,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:11:17,225 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3481
en_de Dev loss: 0.8580 r:0.2308
en_zh Dev loss: 0.7752 r:0.4513
ro_en Dev loss: 0.3428 r:0.8247
et_en Dev loss: 0.4322 r:0.7076
si_en Dev loss: 0.7025 r:0.6007
ne_en Dev loss: 0.3927 r:0.7531
ru_en Dev loss: 0.4394 r:0.7425
Current avg r:0.6158 Best avg r: 0.6324
21:15:47,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:17:18,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:18:48,866 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3129
en_de Dev loss: 0.8544 r:0.2260
en_zh Dev loss: 0.7421 r:0.4553
ro_en Dev loss: 0.3292 r:0.8227
et_en Dev loss: 0.3884 r:0.7010
si_en Dev loss: 0.7519 r:0.5897
ne_en Dev loss: 0.3929 r:0.7563
ru_en Dev loss: 0.4654 r:0.7317
Current avg r:0.6118 Best avg r: 0.6324
21:23:19,444 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:24:50,20 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:26:20,574 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3451
en_de Dev loss: 0.8929 r:0.1751
en_zh Dev loss: 0.7610 r:0.4501
ro_en Dev loss: 0.3218 r:0.8240
et_en Dev loss: 0.3967 r:0.6938
si_en Dev loss: 0.7430 r:0.5943
ne_en Dev loss: 0.3835 r:0.7552
ru_en Dev loss: 0.4294 r:0.7406
Current avg r:0.6047 Best avg r: 0.6324
21:30:51,280 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:32:21,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:33:52,413 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3538
en_de Dev loss: 0.8727 r:0.1812
en_zh Dev loss: 0.7663 r:0.4479
ro_en Dev loss: 0.3539 r:0.8170
et_en Dev loss: 0.4034 r:0.6879
si_en Dev loss: 0.9801 r:0.5778
ne_en Dev loss: 0.6086 r:0.7534
ru_en Dev loss: 0.4762 r:0.7199
Current avg r:0.5979 Best avg r: 0.6324
21:38:22,964 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:39:53,516 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:41:24,9 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3606
en_de Dev loss: 0.8873 r:0.1732
en_zh Dev loss: 0.7704 r:0.4420
ro_en Dev loss: 0.3378 r:0.8231
et_en Dev loss: 0.4148 r:0.6906
si_en Dev loss: 0.8377 r:0.5836
ne_en Dev loss: 0.4944 r:0.7473
ru_en Dev loss: 0.4921 r:0.7132
Current avg r:0.5961 Best avg r: 0.6324
21:45:54,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:47:25,203 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:48:55,695 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3534
en_de Dev loss: 0.8888 r:0.2073
en_zh Dev loss: 0.7895 r:0.4356
ro_en Dev loss: 0.3247 r:0.8245
et_en Dev loss: 0.3925 r:0.6940
si_en Dev loss: 0.8303 r:0.5881
ne_en Dev loss: 0.4826 r:0.7453
ru_en Dev loss: 0.5319 r:0.6983
Current avg r:0.5990 Best avg r: 0.6324
21:53:26,369 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:54:56,942 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:56:27,505 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3496
en_de Dev loss: 0.8543 r:0.2150
en_zh Dev loss: 0.7299 r:0.4371
ro_en Dev loss: 0.2990 r:0.8257
et_en Dev loss: 0.3909 r:0.6967
si_en Dev loss: 0.7040 r:0.5898
ne_en Dev loss: 0.4335 r:0.7464
ru_en Dev loss: 0.4150 r:0.7288
Current avg r:0.6057 Best avg r: 0.6324
22:00:58,237 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:01:37,66 root INFO 
id:ro_en cur r: 0.8360 best r: 0.8360
22:02:28,865 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:03:59,438 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3486
en_de Dev loss: 0.8848 r:0.1899
en_zh Dev loss: 0.7344 r:0.4668
ro_en Dev loss: 0.3117 r:0.8330
et_en Dev loss: 0.4440 r:0.7064
si_en Dev loss: 0.6339 r:0.6124
ne_en Dev loss: 0.3818 r:0.7527
ru_en Dev loss: 0.3952 r:0.7541
Current avg r:0.6165 Best avg r: 0.6324
22:08:30,116 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:10:00,700 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:11:31,234 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3307
en_de Dev loss: 0.8701 r:0.2070
en_zh Dev loss: 0.7469 r:0.4542
ro_en Dev loss: 0.3266 r:0.8253
et_en Dev loss: 0.4061 r:0.6880
si_en Dev loss: 0.7664 r:0.5872
ne_en Dev loss: 0.4577 r:0.7493
ru_en Dev loss: 0.4573 r:0.7214
Current avg r:0.6046 Best avg r: 0.6324
22:16:01,984 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:17:32,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:19:03,213 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3320
en_de Dev loss: 0.8722 r:0.2234
en_zh Dev loss: 0.7650 r:0.4519
ro_en Dev loss: 0.3340 r:0.8265
et_en Dev loss: 0.4154 r:0.6938
si_en Dev loss: 0.6903 r:0.5952
ne_en Dev loss: 0.4559 r:0.7514
ru_en Dev loss: 0.4779 r:0.7206
Current avg r:0.6090 Best avg r: 0.6324
22:23:35,476 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:25:05,958 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:26:36,434 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3041
en_de Dev loss: 0.8570 r:0.2111
en_zh Dev loss: 0.7714 r:0.4384
ro_en Dev loss: 0.3283 r:0.8223
et_en Dev loss: 0.4033 r:0.6912
si_en Dev loss: 0.8405 r:0.5780
ne_en Dev loss: 0.5315 r:0.7407
ru_en Dev loss: 0.4592 r:0.7208
Current avg r:0.6004 Best avg r: 0.6324
22:31:07,72 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:32:37,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:34:08,202 root INFO Epoch 4 Global steps: 43400 Train loss: 0.2926
en_de Dev loss: 0.8978 r:0.2070
en_zh Dev loss: 0.8241 r:0.4544
ro_en Dev loss: 0.3594 r:0.8277
et_en Dev loss: 0.4356 r:0.6994
si_en Dev loss: 0.7552 r:0.5960
ne_en Dev loss: 0.4043 r:0.7447
ru_en Dev loss: 0.4387 r:0.7532
Current avg r:0.6118 Best avg r: 0.6324
22:38:38,917 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:40:09,504 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:41:40,97 root INFO Epoch 4 Global steps: 44100 Train loss: 0.2984
en_de Dev loss: 0.9080 r:0.1843
en_zh Dev loss: 0.8044 r:0.4477
ro_en Dev loss: 0.3461 r:0.8241
et_en Dev loss: 0.4095 r:0.6906
si_en Dev loss: 0.7420 r:0.5814
ne_en Dev loss: 0.4691 r:0.7361
ru_en Dev loss: 0.4725 r:0.7257
Current avg r:0.5986 Best avg r: 0.6324
22:46:10,802 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:47:41,366 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:49:11,899 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2953
en_de Dev loss: 0.8962 r:0.2008
en_zh Dev loss: 0.8040 r:0.4472
ro_en Dev loss: 0.3478 r:0.8221
et_en Dev loss: 0.4405 r:0.6884
si_en Dev loss: 0.7403 r:0.5848
ne_en Dev loss: 0.4085 r:0.7432
ru_en Dev loss: 0.4335 r:0.7381
Current avg r:0.6035 Best avg r: 0.6324
22:53:42,615 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:55:13,209 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:56:43,796 root INFO Epoch 4 Global steps: 45500 Train loss: 0.2921
en_de Dev loss: 0.9027 r:0.2119
en_zh Dev loss: 0.8683 r:0.4285
ro_en Dev loss: 0.3877 r:0.8195
et_en Dev loss: 0.4392 r:0.6717
si_en Dev loss: 0.9700 r:0.5634
ne_en Dev loss: 0.6098 r:0.7357
ru_en Dev loss: 0.5050 r:0.7182
Current avg r:0.5927 Best avg r: 0.6324
23:01:14,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:02:45,39 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:04:15,561 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2986
en_de Dev loss: 0.8878 r:0.2007
en_zh Dev loss: 0.8122 r:0.4376
ro_en Dev loss: 0.3433 r:0.8242
et_en Dev loss: 0.4008 r:0.6892
si_en Dev loss: 0.7632 r:0.5810
ne_en Dev loss: 0.4622 r:0.7386
ru_en Dev loss: 0.4981 r:0.7138
Current avg r:0.5979 Best avg r: 0.6324
23:08:46,182 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:10:16,736 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:11:47,241 root INFO Epoch 4 Global steps: 46900 Train loss: 0.2764
en_de Dev loss: 0.8732 r:0.2128
en_zh Dev loss: 0.7938 r:0.4309
ro_en Dev loss: 0.3500 r:0.8210
et_en Dev loss: 0.4337 r:0.6700
si_en Dev loss: 0.8485 r:0.5679
ne_en Dev loss: 0.5450 r:0.7314
ru_en Dev loss: 0.4876 r:0.7054
Current avg r:0.5913 Best avg r: 0.6324
23:16:17,725 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:17:48,226 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:19:18,691 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2844
en_de Dev loss: 0.8969 r:0.1863
en_zh Dev loss: 0.8088 r:0.4289
ro_en Dev loss: 0.3233 r:0.8276
et_en Dev loss: 0.4399 r:0.6865
si_en Dev loss: 0.7163 r:0.5886
ne_en Dev loss: 0.4624 r:0.7358
ru_en Dev loss: 0.4553 r:0.7295
Current avg r:0.5976 Best avg r: 0.6324
23:23:49,130 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:25:19,626 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:26:50,100 root INFO Epoch 4 Global steps: 48300 Train loss: 0.2866
en_de Dev loss: 0.8667 r:0.2030
en_zh Dev loss: 0.7569 r:0.4393
ro_en Dev loss: 0.3119 r:0.8231
et_en Dev loss: 0.4379 r:0.6855
si_en Dev loss: 0.7269 r:0.5825
ne_en Dev loss: 0.4253 r:0.7438
ru_en Dev loss: 0.3916 r:0.7467
Current avg r:0.6034 Best avg r: 0.6324
23:31:20,614 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:32:51,137 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:34:21,625 root INFO Epoch 4 Global steps: 49000 Train loss: 0.2788
en_de Dev loss: 0.8916 r:0.2024
en_zh Dev loss: 0.8181 r:0.4394
ro_en Dev loss: 0.3458 r:0.8240
et_en Dev loss: 0.4490 r:0.6803
si_en Dev loss: 0.8470 r:0.5747
ne_en Dev loss: 0.5220 r:0.7384
ru_en Dev loss: 0.5601 r:0.7012
Current avg r:0.5943 Best avg r: 0.6324
23:38:52,224 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:40:22,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:41:53,179 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2804
en_de Dev loss: 0.8696 r:0.2034
en_zh Dev loss: 0.7774 r:0.4398
ro_en Dev loss: 0.3413 r:0.8187
et_en Dev loss: 0.4347 r:0.6680
si_en Dev loss: 0.8914 r:0.5679
ne_en Dev loss: 0.6071 r:0.7350
ru_en Dev loss: 0.4560 r:0.7238
Current avg r:0.5938 Best avg r: 0.6324
23:46:23,674 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:47:54,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:49:24,563 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2802
en_de Dev loss: 0.8844 r:0.2025
en_zh Dev loss: 0.8029 r:0.4322
ro_en Dev loss: 0.3441 r:0.8210
et_en Dev loss: 0.4325 r:0.6808
si_en Dev loss: 0.7552 r:0.5805
ne_en Dev loss: 0.4740 r:0.7381
ru_en Dev loss: 0.4751 r:0.7184
Current avg r:0.5962 Best avg r: 0.6324
23:53:55,85 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:55:25,560 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:56:55,963 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2806
en_de Dev loss: 0.8804 r:0.1890
en_zh Dev loss: 0.7528 r:0.4418
ro_en Dev loss: 0.3205 r:0.8236
et_en Dev loss: 0.4598 r:0.6910
si_en Dev loss: 0.7164 r:0.5837
ne_en Dev loss: 0.4277 r:0.7400
ru_en Dev loss: 0.4245 r:0.7280
Current avg r:0.5996 Best avg r: 0.6324
00:01:26,362 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:02:56,780 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:04:27,200 root INFO Epoch 4 Global steps: 51800 Train loss: 0.2774
en_de Dev loss: 0.8837 r:0.1945
en_zh Dev loss: 0.7455 r:0.4416
ro_en Dev loss: 0.3111 r:0.8255
et_en Dev loss: 0.4112 r:0.6805
si_en Dev loss: 0.7782 r:0.5711
ne_en Dev loss: 0.4403 r:0.7430
ru_en Dev loss: 0.4126 r:0.7408
Current avg r:0.5996 Best avg r: 0.6324
00:08:57,673 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:10:28,140 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:11:58,610 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2677
en_de Dev loss: 0.8760 r:0.2033
en_zh Dev loss: 0.7616 r:0.4495
ro_en Dev loss: 0.3485 r:0.8169
et_en Dev loss: 0.4566 r:0.6710
si_en Dev loss: 0.8550 r:0.5535
ne_en Dev loss: 0.4931 r:0.7295
ru_en Dev loss: 0.4569 r:0.7152
Current avg r:0.5913 Best avg r: 0.6324
00:16:30,668 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:18:01,176 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:19:31,641 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2447
en_de Dev loss: 0.8738 r:0.1960
en_zh Dev loss: 0.7633 r:0.4449
ro_en Dev loss: 0.3158 r:0.8271
et_en Dev loss: 0.4284 r:0.6831
si_en Dev loss: 0.8126 r:0.5743
ne_en Dev loss: 0.4813 r:0.7333
ru_en Dev loss: 0.4252 r:0.7382
Current avg r:0.5996 Best avg r: 0.6324
00:24:02,40 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:25:32,530 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:27:02,970 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2405
en_de Dev loss: 0.8912 r:0.2151
en_zh Dev loss: 0.8100 r:0.4526
ro_en Dev loss: 0.3531 r:0.8265
et_en Dev loss: 0.4723 r:0.6802
si_en Dev loss: 0.7968 r:0.5753
ne_en Dev loss: 0.4573 r:0.7336
ru_en Dev loss: 0.4740 r:0.7272
Current avg r:0.6015 Best avg r: 0.6324
00:31:33,394 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:33:03,887 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:34:34,320 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2433
en_de Dev loss: 0.8801 r:0.2060
en_zh Dev loss: 0.8061 r:0.4422
ro_en Dev loss: 0.3252 r:0.8301
et_en Dev loss: 0.4491 r:0.6855
si_en Dev loss: 0.7931 r:0.5775
ne_en Dev loss: 0.4591 r:0.7324
ru_en Dev loss: 0.4769 r:0.7225
Current avg r:0.5995 Best avg r: 0.6324
00:39:04,789 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:40:35,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:42:05,845 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2431
en_de Dev loss: 0.9194 r:0.1812
en_zh Dev loss: 0.8007 r:0.4509
ro_en Dev loss: 0.3604 r:0.8247
et_en Dev loss: 0.4712 r:0.6747
si_en Dev loss: 0.8388 r:0.5709
ne_en Dev loss: 0.5128 r:0.7303
ru_en Dev loss: 0.4860 r:0.7213
Current avg r:0.5934 Best avg r: 0.6324
00:46:36,383 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:48:06,914 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:49:37,394 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2413
en_de Dev loss: 0.8626 r:0.2100
en_zh Dev loss: 0.7818 r:0.4292
ro_en Dev loss: 0.3303 r:0.8186
et_en Dev loss: 0.4330 r:0.6661
si_en Dev loss: 0.8816 r:0.5508
ne_en Dev loss: 0.5854 r:0.7248
ru_en Dev loss: 0.4263 r:0.7291
Current avg r:0.5898 Best avg r: 0.6324
00:54:07,918 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:55:38,431 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:57:08,917 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2426
en_de Dev loss: 0.8541 r:0.2226
en_zh Dev loss: 0.7687 r:0.4415
ro_en Dev loss: 0.3314 r:0.8207
et_en Dev loss: 0.4486 r:0.6710
si_en Dev loss: 0.8072 r:0.5583
ne_en Dev loss: 0.5274 r:0.7226
ru_en Dev loss: 0.4344 r:0.7242
Current avg r:0.5944 Best avg r: 0.6324
01:01:39,455 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:03:09,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:04:40,442 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2368
en_de Dev loss: 0.8825 r:0.2146
en_zh Dev loss: 0.8390 r:0.4286
ro_en Dev loss: 0.3677 r:0.8213
et_en Dev loss: 0.4728 r:0.6621
si_en Dev loss: 0.9798 r:0.5496
ne_en Dev loss: 0.5838 r:0.7223
ru_en Dev loss: 0.5015 r:0.7140
Current avg r:0.5875 Best avg r: 0.6324
01:09:11,24 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:10:41,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:12:11,978 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2500
en_de Dev loss: 0.9069 r:0.2208
en_zh Dev loss: 0.8380 r:0.4297
ro_en Dev loss: 0.3614 r:0.8243
et_en Dev loss: 0.4566 r:0.6707
si_en Dev loss: 0.8203 r:0.5647
ne_en Dev loss: 0.4655 r:0.7316
ru_en Dev loss: 0.4851 r:0.7187
Current avg r:0.5943 Best avg r: 0.6324
01:16:42,376 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:18:12,816 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:19:43,266 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2405
en_de Dev loss: 0.8743 r:0.2230
en_zh Dev loss: 0.8187 r:0.4366
ro_en Dev loss: 0.3225 r:0.8297
et_en Dev loss: 0.4296 r:0.6836
si_en Dev loss: 0.7888 r:0.5756
ne_en Dev loss: 0.4495 r:0.7295
ru_en Dev loss: 0.4654 r:0.7260
Current avg r:0.6006 Best avg r: 0.6324
01:24:13,814 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:25:44,339 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:27:14,805 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2376
en_de Dev loss: 0.8953 r:0.2256
en_zh Dev loss: 0.8706 r:0.4309
ro_en Dev loss: 0.3932 r:0.8220
et_en Dev loss: 0.5234 r:0.6654
si_en Dev loss: 0.8970 r:0.5598
ne_en Dev loss: 0.5197 r:0.7247
ru_en Dev loss: 0.4880 r:0.7226
Current avg r:0.5930 Best avg r: 0.6324
01:31:45,259 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:33:15,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:34:46,240 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2412
en_de Dev loss: 0.8607 r:0.2418
en_zh Dev loss: 0.7974 r:0.4554
ro_en Dev loss: 0.3393 r:0.8289
et_en Dev loss: 0.4939 r:0.6796
si_en Dev loss: 0.8103 r:0.5729
ne_en Dev loss: 0.4573 r:0.7265
ru_en Dev loss: 0.4200 r:0.7507
Current avg r:0.6080 Best avg r: 0.6324
01:39:16,730 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:40:47,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:42:17,495 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2454
en_de Dev loss: 0.8871 r:0.2161
en_zh Dev loss: 0.8523 r:0.4369
ro_en Dev loss: 0.3668 r:0.8226
et_en Dev loss: 0.4506 r:0.6736
si_en Dev loss: 0.8765 r:0.5598
ne_en Dev loss: 0.5053 r:0.7286
ru_en Dev loss: 0.5028 r:0.7110
Current avg r:0.5926 Best avg r: 0.6324
01:46:47,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:48:18,253 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:49:48,620 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2400
en_de Dev loss: 0.8648 r:0.2225
en_zh Dev loss: 0.7590 r:0.4453
ro_en Dev loss: 0.3038 r:0.8281
et_en Dev loss: 0.4481 r:0.6791
si_en Dev loss: 0.7320 r:0.5708
ne_en Dev loss: 0.4405 r:0.7297
ru_en Dev loss: 0.4251 r:0.7316
Current avg r:0.6010 Best avg r: 0.6324
01:54:18,876 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:55:49,260 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:57:19,623 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2359
en_de Dev loss: 0.8930 r:0.2020
en_zh Dev loss: 0.8195 r:0.4370
ro_en Dev loss: 0.3746 r:0.8241
et_en Dev loss: 0.4469 r:0.6774
si_en Dev loss: 0.9623 r:0.5616
ne_en Dev loss: 0.5232 r:0.7330
ru_en Dev loss: 0.4977 r:0.7225
Current avg r:0.5939 Best avg r: 0.6324
02:01:53,985 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:03:26,244 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:04:58,470 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2257
en_de Dev loss: 0.8699 r:0.2318
en_zh Dev loss: 0.7910 r:0.4544
ro_en Dev loss: 0.3515 r:0.8207
et_en Dev loss: 0.4533 r:0.6739
si_en Dev loss: 0.8959 r:0.5589
ne_en Dev loss: 0.5229 r:0.7245
ru_en Dev loss: 0.4650 r:0.7257
Current avg r:0.5986 Best avg r: 0.6324
02:09:35,546 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:11:07,396 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:12:39,231 root INFO Epoch 6 Global steps: 63700 Train loss: 0.1970
en_de Dev loss: 0.8769 r:0.2356
en_zh Dev loss: 0.8195 r:0.4475
ro_en Dev loss: 0.3737 r:0.8240
et_en Dev loss: 0.4558 r:0.6750
si_en Dev loss: 0.9331 r:0.5575
ne_en Dev loss: 0.5428 r:0.7263
ru_en Dev loss: 0.4970 r:0.7147
Current avg r:0.5972 Best avg r: 0.6324
02:17:14,649 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:18:46,458 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:20:18,249 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2056
en_de Dev loss: 0.8829 r:0.2357
en_zh Dev loss: 0.7941 r:0.4565
ro_en Dev loss: 0.3671 r:0.8244
et_en Dev loss: 0.4761 r:0.6765
si_en Dev loss: 0.8940 r:0.5550
ne_en Dev loss: 0.5050 r:0.7238
ru_en Dev loss: 0.4452 r:0.7380
Current avg r:0.6014 Best avg r: 0.6324
02:24:53,525 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:26:25,333 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:27:57,85 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2056
en_de Dev loss: 0.8892 r:0.2266
en_zh Dev loss: 0.8256 r:0.4447
ro_en Dev loss: 0.3763 r:0.8214
et_en Dev loss: 0.4842 r:0.6623
si_en Dev loss: 0.9516 r:0.5461
ne_en Dev loss: 0.5663 r:0.7216
ru_en Dev loss: 0.4599 r:0.7269
Current avg r:0.5928 Best avg r: 0.6324
02:32:30,58 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:34:01,131 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:35:32,178 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2072
en_de Dev loss: 0.9025 r:0.2258
en_zh Dev loss: 0.8162 r:0.4426
ro_en Dev loss: 0.3465 r:0.8233
et_en Dev loss: 0.4557 r:0.6701
si_en Dev loss: 0.8316 r:0.5594
ne_en Dev loss: 0.5180 r:0.7340
ru_en Dev loss: 0.4583 r:0.7268
Current avg r:0.5974 Best avg r: 0.6324
02:40:04,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:41:36,109 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:43:07,722 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2060
en_de Dev loss: 0.8707 r:0.2452
en_zh Dev loss: 0.7829 r:0.4432
ro_en Dev loss: 0.3270 r:0.8249
et_en Dev loss: 0.4738 r:0.6696
si_en Dev loss: 0.7566 r:0.5623
ne_en Dev loss: 0.4681 r:0.7233
ru_en Dev loss: 0.4558 r:0.7158
Current avg r:0.5977 Best avg r: 0.6324
02:47:42,340 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:49:13,981 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:50:45,605 root INFO Epoch 6 Global steps: 67200 Train loss: 0.1943
en_de Dev loss: 0.8872 r:0.2163
en_zh Dev loss: 0.7857 r:0.4414
ro_en Dev loss: 0.3364 r:0.8219
et_en Dev loss: 0.4931 r:0.6730
si_en Dev loss: 0.8230 r:0.5499
ne_en Dev loss: 0.4882 r:0.7166
ru_en Dev loss: 0.4626 r:0.7144
Current avg r:0.5905 Best avg r: 0.6324
02:55:19,838 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:56:51,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:58:23,90 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2038
en_de Dev loss: 0.9028 r:0.2298
en_zh Dev loss: 0.8185 r:0.4524
ro_en Dev loss: 0.3564 r:0.8233
et_en Dev loss: 0.4977 r:0.6695
si_en Dev loss: 0.8444 r:0.5648
ne_en Dev loss: 0.4806 r:0.7239
ru_en Dev loss: 0.4816 r:0.7308
Current avg r:0.5992 Best avg r: 0.6324
03:02:57,430 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:04:28,519 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:05:59,432 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2049
en_de Dev loss: 0.8692 r:0.2163
en_zh Dev loss: 0.7739 r:0.4451
ro_en Dev loss: 0.3252 r:0.8229
et_en Dev loss: 0.4428 r:0.6649
si_en Dev loss: 0.9238 r:0.5489
ne_en Dev loss: 0.5595 r:0.7227
ru_en Dev loss: 0.4613 r:0.7209
Current avg r:0.5917 Best avg r: 0.6324
03:10:31,517 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:12:02,548 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:13:33,477 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2122
en_de Dev loss: 0.8967 r:0.2080
en_zh Dev loss: 0.8314 r:0.4423
ro_en Dev loss: 0.3625 r:0.8218
et_en Dev loss: 0.4864 r:0.6598
si_en Dev loss: 0.8625 r:0.5574
ne_en Dev loss: 0.5345 r:0.7252
ru_en Dev loss: 0.4997 r:0.7088
Current avg r:0.5891 Best avg r: 0.6324
03:18:06,967 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:19:38,610 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:21:10,173 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2069
en_de Dev loss: 0.8676 r:0.2202
en_zh Dev loss: 0.7575 r:0.4450
ro_en Dev loss: 0.3021 r:0.8261
et_en Dev loss: 0.4420 r:0.6625
si_en Dev loss: 0.7522 r:0.5596
ne_en Dev loss: 0.4966 r:0.7250
ru_en Dev loss: 0.4299 r:0.7295
Current avg r:0.5954 Best avg r: 0.6324
03:25:44,425 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:27:16,23 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:28:47,605 root INFO Epoch 6 Global steps: 70700 Train loss: 0.1957
en_de Dev loss: 0.8771 r:0.2211
en_zh Dev loss: 0.7714 r:0.4523
ro_en Dev loss: 0.3211 r:0.8267
et_en Dev loss: 0.4501 r:0.6684
si_en Dev loss: 0.7833 r:0.5638
ne_en Dev loss: 0.4939 r:0.7238
ru_en Dev loss: 0.4463 r:0.7280
Current avg r:0.5977 Best avg r: 0.6324
03:33:21,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:34:53,268 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:36:24,822 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2081
en_de Dev loss: 0.8822 r:0.2246
en_zh Dev loss: 0.7831 r:0.4546
ro_en Dev loss: 0.3290 r:0.8257
et_en Dev loss: 0.4554 r:0.6668
si_en Dev loss: 0.8222 r:0.5612
ne_en Dev loss: 0.5158 r:0.7306
ru_en Dev loss: 0.4655 r:0.7286
Current avg r:0.5988 Best avg r: 0.6324
03:40:57,804 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:42:28,872 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:43:59,907 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2044
en_de Dev loss: 0.8731 r:0.2174
en_zh Dev loss: 0.7992 r:0.4426
ro_en Dev loss: 0.3179 r:0.8236
et_en Dev loss: 0.4850 r:0.6759
si_en Dev loss: 0.8145 r:0.5615
ne_en Dev loss: 0.4764 r:0.7245
ru_en Dev loss: 0.4189 r:0.7406
Current avg r:0.5980 Best avg r: 0.6324
03:48:31,773 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:50:03,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:51:34,867 root INFO Epoch 6 Global steps: 72800 Train loss: 0.1920
en_de Dev loss: 0.8930 r:0.2285
en_zh Dev loss: 0.8190 r:0.4519
ro_en Dev loss: 0.3584 r:0.8229
et_en Dev loss: 0.5243 r:0.6714
si_en Dev loss: 0.8893 r:0.5585
ne_en Dev loss: 0.5200 r:0.7217
ru_en Dev loss: 0.4660 r:0.7389
Current avg r:0.5991 Best avg r: 0.6324
03:56:09,297 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:57:40,845 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:59:12,375 root INFO Epoch 6 Global steps: 73500 Train loss: 0.1892
en_de Dev loss: 0.8735 r:0.2182
en_zh Dev loss: 0.7618 r:0.4506
ro_en Dev loss: 0.3111 r:0.8284
et_en Dev loss: 0.4778 r:0.6759
si_en Dev loss: 0.7663 r:0.5656
ne_en Dev loss: 0.4485 r:0.7225
ru_en Dev loss: 0.4214 r:0.7388
Current avg r:0.6000 Best avg r: 0.6324
04:03:47,947 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:05:19,511 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:06:51,87 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1697
en_de Dev loss: 0.8746 r:0.2173
en_zh Dev loss: 0.7633 r:0.4429
ro_en Dev loss: 0.3048 r:0.8262
et_en Dev loss: 0.4627 r:0.6709
si_en Dev loss: 0.7824 r:0.5535
ne_en Dev loss: 0.4736 r:0.7217
ru_en Dev loss: 0.4265 r:0.7340
Current avg r:0.5952 Best avg r: 0.6324
04:11:25,601 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:12:56,973 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:14:27,972 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1726
en_de Dev loss: 0.8964 r:0.2250
en_zh Dev loss: 0.7989 r:0.4455
ro_en Dev loss: 0.3458 r:0.8248
et_en Dev loss: 0.5005 r:0.6694
si_en Dev loss: 0.8187 r:0.5580
ne_en Dev loss: 0.4822 r:0.7185
ru_en Dev loss: 0.4457 r:0.7407
Current avg r:0.5974 Best avg r: 0.6324
04:18:59,717 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:20:30,737 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:01,723 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1840
en_de Dev loss: 0.8804 r:0.2234
en_zh Dev loss: 0.8275 r:0.4344
ro_en Dev loss: 0.3481 r:0.8244
et_en Dev loss: 0.4647 r:0.6616
si_en Dev loss: 0.8659 r:0.5499
ne_en Dev loss: 0.5555 r:0.7172
ru_en Dev loss: 0.4818 r:0.7273
Current avg r:0.5912 Best avg r: 0.6324
04:26:35,994 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:07,614 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:29:39,178 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1899
en_de Dev loss: 0.8544 r:0.2269
en_zh Dev loss: 0.7673 r:0.4296
ro_en Dev loss: 0.3259 r:0.8169
et_en Dev loss: 0.4406 r:0.6586
si_en Dev loss: 0.8133 r:0.5468
ne_en Dev loss: 0.4939 r:0.7202
ru_en Dev loss: 0.4438 r:0.7161
Current avg r:0.5879 Best avg r: 0.6324
04:34:13,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:35:44,750 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:16,336 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1819
en_de Dev loss: 0.8640 r:0.2285
en_zh Dev loss: 0.7872 r:0.4456
ro_en Dev loss: 0.3326 r:0.8246
et_en Dev loss: 0.4964 r:0.6616
si_en Dev loss: 0.9109 r:0.5405
ne_en Dev loss: 0.5366 r:0.7145
ru_en Dev loss: 0.4509 r:0.7286
Current avg r:0.5920 Best avg r: 0.6324
04:41:50,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:21,952 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:44:53,533 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1802
en_de Dev loss: 0.8748 r:0.2286
en_zh Dev loss: 0.7804 r:0.4518
ro_en Dev loss: 0.3359 r:0.8252
et_en Dev loss: 0.4721 r:0.6645
si_en Dev loss: 0.8351 r:0.5597
ne_en Dev loss: 0.5185 r:0.7178
ru_en Dev loss: 0.4347 r:0.7372
Current avg r:0.5978 Best avg r: 0.6324
04:49:26,174 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:50:57,246 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:28,314 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1685
en_de Dev loss: 0.8880 r:0.2214
en_zh Dev loss: 0.8047 r:0.4525
ro_en Dev loss: 0.3705 r:0.8224
et_en Dev loss: 0.4958 r:0.6646
si_en Dev loss: 0.9344 r:0.5495
ne_en Dev loss: 0.5641 r:0.7191
ru_en Dev loss: 0.4707 r:0.7338
Current avg r:0.5948 Best avg r: 0.6324
04:57:01,169 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:32,768 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:04,265 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1702
en_de Dev loss: 0.8949 r:0.2205
en_zh Dev loss: 0.7983 r:0.4626
ro_en Dev loss: 0.3618 r:0.8233
et_en Dev loss: 0.4692 r:0.6681
si_en Dev loss: 0.8989 r:0.5543
ne_en Dev loss: 0.5416 r:0.7243
ru_en Dev loss: 0.4549 r:0.7413
Current avg r:0.5992 Best avg r: 0.6324
05:04:38,317 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:09,937 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:41,535 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1819
en_de Dev loss: 0.8815 r:0.2130
en_zh Dev loss: 0.7696 r:0.4596
ro_en Dev loss: 0.3102 r:0.8250
et_en Dev loss: 0.4669 r:0.6736
si_en Dev loss: 0.8165 r:0.5562
ne_en Dev loss: 0.4779 r:0.7171
ru_en Dev loss: 0.4263 r:0.7389
Current avg r:0.5976 Best avg r: 0.6324
05:12:16,241 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:47,805 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:19,319 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1766
en_de Dev loss: 0.9069 r:0.2078
en_zh Dev loss: 0.8327 r:0.4578
ro_en Dev loss: 0.3939 r:0.8182
et_en Dev loss: 0.4683 r:0.6575
si_en Dev loss: 0.9934 r:0.5431
ne_en Dev loss: 0.6047 r:0.7142
ru_en Dev loss: 0.4794 r:0.7319
Current avg r:0.5901 Best avg r: 0.6324
05:19:53,996 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:25,73 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:56,138 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1685
en_de Dev loss: 0.8761 r:0.2222
en_zh Dev loss: 0.7754 r:0.4588
ro_en Dev loss: 0.3330 r:0.8190
et_en Dev loss: 0.4738 r:0.6614
si_en Dev loss: 0.8252 r:0.5527
ne_en Dev loss: 0.4763 r:0.7168
ru_en Dev loss: 0.4333 r:0.7307
Current avg r:0.5945 Best avg r: 0.6324
05:27:28,135 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:59,426 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:30,679 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1750
en_de Dev loss: 0.8872 r:0.2112
en_zh Dev loss: 0.7849 r:0.4554
ro_en Dev loss: 0.3439 r:0.8189
et_en Dev loss: 0.4572 r:0.6606
si_en Dev loss: 0.9209 r:0.5435
ne_en Dev loss: 0.5718 r:0.7127
ru_en Dev loss: 0.4519 r:0.7292
Current avg r:0.5902 Best avg r: 0.6324
05:35:02,524 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:33,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:38:04,743 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1798
en_de Dev loss: 0.8736 r:0.2111
en_zh Dev loss: 0.7623 r:0.4513
ro_en Dev loss: 0.3253 r:0.8215
et_en Dev loss: 0.4651 r:0.6690
si_en Dev loss: 0.8288 r:0.5574
ne_en Dev loss: 0.5177 r:0.7191
ru_en Dev loss: 0.4212 r:0.7378
Current avg r:0.5953 Best avg r: 0.6324
05:42:36,818 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:44:07,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:39,33 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1723
en_de Dev loss: 0.8990 r:0.2130
en_zh Dev loss: 0.8326 r:0.4549
ro_en Dev loss: 0.3560 r:0.8231
et_en Dev loss: 0.4766 r:0.6630
si_en Dev loss: 0.9127 r:0.5519
ne_en Dev loss: 0.5646 r:0.7178
ru_en Dev loss: 0.4561 r:0.7352
Current avg r:0.5941 Best avg r: 0.6324
05:50:10,969 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:41,618 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:53:12,242 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1718
en_de Dev loss: 0.9024 r:0.2271
en_zh Dev loss: 0.8235 r:0.4539
ro_en Dev loss: 0.3700 r:0.8183
et_en Dev loss: 0.5194 r:0.6552
si_en Dev loss: 0.9182 r:0.5434
ne_en Dev loss: 0.5416 r:0.7193
ru_en Dev loss: 0.4772 r:0.7206
Current avg r:0.5911 Best avg r: 0.6324
05:57:44,807 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:59:15,474 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:46,118 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1608
en_de Dev loss: 0.9024 r:0.2189
en_zh Dev loss: 0.8007 r:0.4595
ro_en Dev loss: 0.3442 r:0.8191
et_en Dev loss: 0.5030 r:0.6639
si_en Dev loss: 0.8103 r:0.5573
ne_en Dev loss: 0.4978 r:0.7133
ru_en Dev loss: 0.4703 r:0.7249
Current avg r:0.5938 Best avg r: 0.6324
06:05:17,10 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:47,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:08:18,297 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1556
en_de Dev loss: 0.8836 r:0.2089
en_zh Dev loss: 0.7702 r:0.4539
ro_en Dev loss: 0.3250 r:0.8193
et_en Dev loss: 0.4557 r:0.6555
si_en Dev loss: 0.8500 r:0.5448
ne_en Dev loss: 0.5142 r:0.7104
ru_en Dev loss: 0.4390 r:0.7328
Current avg r:0.5894 Best avg r: 0.6324
06:12:49,353 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:14:20,43 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:50,721 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1484
en_de Dev loss: 0.9285 r:0.2229
en_zh Dev loss: 0.8486 r:0.4587
ro_en Dev loss: 0.3839 r:0.8206
et_en Dev loss: 0.5058 r:0.6608
si_en Dev loss: 1.0338 r:0.5335
ne_en Dev loss: 0.6222 r:0.7030
ru_en Dev loss: 0.5284 r:0.7236
Current avg r:0.5890 Best avg r: 0.6324
06:20:21,605 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:52,269 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:23:22,807 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1516
en_de Dev loss: 0.9022 r:0.1985
en_zh Dev loss: 0.8238 r:0.4393
ro_en Dev loss: 0.3512 r:0.8196
et_en Dev loss: 0.4703 r:0.6597
si_en Dev loss: 0.8835 r:0.5425
ne_en Dev loss: 0.5426 r:0.7125
ru_en Dev loss: 0.4679 r:0.7230
Current avg r:0.5850 Best avg r: 0.6324
06:27:53,386 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:29:24,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:54,635 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1543
en_de Dev loss: 0.9071 r:0.2031
en_zh Dev loss: 0.8247 r:0.4572
ro_en Dev loss: 0.3649 r:0.8215
et_en Dev loss: 0.5031 r:0.6694
si_en Dev loss: 0.9032 r:0.5471
ne_en Dev loss: 0.5724 r:0.7061
ru_en Dev loss: 0.4656 r:0.7375
Current avg r:0.5917 Best avg r: 0.6324
06:35:25,539 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:56,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:38:26,764 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1489
en_de Dev loss: 0.9225 r:0.1809
en_zh Dev loss: 0.8229 r:0.4535
ro_en Dev loss: 0.3508 r:0.8214
et_en Dev loss: 0.4753 r:0.6609
si_en Dev loss: 0.9321 r:0.5443
ne_en Dev loss: 0.6019 r:0.7174
ru_en Dev loss: 0.4653 r:0.7353
Current avg r:0.5877 Best avg r: 0.6324
06:42:57,765 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:44:28,378 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:58,961 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1601
en_de Dev loss: 0.9363 r:0.1895
en_zh Dev loss: 0.8271 r:0.4578
ro_en Dev loss: 0.3563 r:0.8222
et_en Dev loss: 0.4960 r:0.6711
si_en Dev loss: 0.8778 r:0.5545
ne_en Dev loss: 0.5056 r:0.7201
ru_en Dev loss: 0.4650 r:0.7386
Current avg r:0.5934 Best avg r: 0.6324
06:50:29,679 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:52:00,279 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:53:30,851 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1504
en_de Dev loss: 0.9261 r:0.2044
en_zh Dev loss: 0.8499 r:0.4574
ro_en Dev loss: 0.3511 r:0.8230
et_en Dev loss: 0.4860 r:0.6708
si_en Dev loss: 0.9148 r:0.5473
ne_en Dev loss: 0.5614 r:0.7182
ru_en Dev loss: 0.4653 r:0.7383
Current avg r:0.5942 Best avg r: 0.6324
06:58:01,578 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:59:32,191 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:01:02,830 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1533
en_de Dev loss: 0.8835 r:0.2365
en_zh Dev loss: 0.7980 r:0.4577
ro_en Dev loss: 0.3393 r:0.8161
et_en Dev loss: 0.4739 r:0.6679
si_en Dev loss: 0.8567 r:0.5436
ne_en Dev loss: 0.5152 r:0.7227
ru_en Dev loss: 0.4310 r:0.7383
Current avg r:0.5975 Best avg r: 0.6324
07:05:33,901 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:07:04,533 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:08:35,177 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1450
en_de Dev loss: 0.8748 r:0.2290
en_zh Dev loss: 0.7562 r:0.4672
ro_en Dev loss: 0.3354 r:0.8188
et_en Dev loss: 0.4722 r:0.6675
si_en Dev loss: 0.8271 r:0.5533
ne_en Dev loss: 0.4996 r:0.7212
ru_en Dev loss: 0.4099 r:0.7462
Current avg r:0.6005 Best avg r: 0.6324
07:13:05,983 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:14:36,616 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:16:07,238 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1548
en_de Dev loss: 0.9023 r:0.2397
en_zh Dev loss: 0.8001 r:0.4683
ro_en Dev loss: 0.3658 r:0.8234
et_en Dev loss: 0.4741 r:0.6676
si_en Dev loss: 0.8720 r:0.5554
ne_en Dev loss: 0.5439 r:0.7242
ru_en Dev loss: 0.4399 r:0.7496
Current avg r:0.6040 Best avg r: 0.6324
07:20:38,105 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:22:08,733 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:23:39,375 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1426
en_de Dev loss: 0.9095 r:0.2158
en_zh Dev loss: 0.7784 r:0.4765
ro_en Dev loss: 0.3418 r:0.8223
et_en Dev loss: 0.4994 r:0.6793
si_en Dev loss: 0.7866 r:0.5642
ne_en Dev loss: 0.4722 r:0.7193
ru_en Dev loss: 0.4095 r:0.7530
Current avg r:0.6043 Best avg r: 0.6324
07:28:10,129 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:29:40,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:31:11,392 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1418
en_de Dev loss: 0.9098 r:0.2258
en_zh Dev loss: 0.8110 r:0.4632
ro_en Dev loss: 0.3562 r:0.8211
et_en Dev loss: 0.4892 r:0.6669
si_en Dev loss: 0.8919 r:0.5388
ne_en Dev loss: 0.5600 r:0.7099
ru_en Dev loss: 0.4764 r:0.7265
Current avg r:0.5932 Best avg r: 0.6324
07:35:42,230 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:37:12,868 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:38:43,501 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1581
en_de Dev loss: 0.9169 r:0.2305
en_zh Dev loss: 0.7988 r:0.4765
ro_en Dev loss: 0.3409 r:0.8219
et_en Dev loss: 0.4995 r:0.6797
si_en Dev loss: 0.8349 r:0.5541
ne_en Dev loss: 0.4989 r:0.7161
ru_en Dev loss: 0.4321 r:0.7449
Current avg r:0.6034 Best avg r: 0.6324
07:43:14,223 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:44:44,833 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:46:15,444 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1446
en_de Dev loss: 0.8998 r:0.2148
en_zh Dev loss: 0.7847 r:0.4511
ro_en Dev loss: 0.3373 r:0.8185
et_en Dev loss: 0.4799 r:0.6698
si_en Dev loss: 0.8128 r:0.5525
ne_en Dev loss: 0.5156 r:0.7188
ru_en Dev loss: 0.4371 r:0.7341
Current avg r:0.5942 Best avg r: 0.6324
07:50:47,783 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:52:18,363 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:53:48,975 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1343
en_de Dev loss: 0.9205 r:0.2109
en_zh Dev loss: 0.8512 r:0.4458
ro_en Dev loss: 0.3496 r:0.8180
et_en Dev loss: 0.4984 r:0.6571
si_en Dev loss: 0.9109 r:0.5372
ne_en Dev loss: 0.5585 r:0.7112
ru_en Dev loss: 0.4627 r:0.7320
Current avg r:0.5874 Best avg r: 0.6324
07:58:19,726 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:59:50,314 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:01:20,915 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1332
en_de Dev loss: 0.9033 r:0.1999
en_zh Dev loss: 0.7839 r:0.4600
ro_en Dev loss: 0.3378 r:0.8195
et_en Dev loss: 0.4770 r:0.6666
si_en Dev loss: 0.8639 r:0.5450
ne_en Dev loss: 0.5537 r:0.7083
ru_en Dev loss: 0.4406 r:0.7342
Current avg r:0.5905 Best avg r: 0.6324
08:05:51,621 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:07:22,231 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:08:52,867 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1337
en_de Dev loss: 0.9235 r:0.2163
en_zh Dev loss: 0.8366 r:0.4692
ro_en Dev loss: 0.3959 r:0.8166
et_en Dev loss: 0.4985 r:0.6645
si_en Dev loss: 0.9631 r:0.5478
ne_en Dev loss: 0.6106 r:0.7170
ru_en Dev loss: 0.4669 r:0.7412
Current avg r:0.5961 Best avg r: 0.6324
08:13:23,678 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:14:54,283 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:16:24,888 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1433
en_de Dev loss: 0.9180 r:0.2100
en_zh Dev loss: 0.8048 r:0.4676
ro_en Dev loss: 0.3584 r:0.8192
et_en Dev loss: 0.4971 r:0.6628
si_en Dev loss: 0.8680 r:0.5495
ne_en Dev loss: 0.5331 r:0.7094
ru_en Dev loss: 0.4285 r:0.7480
Current avg r:0.5952 Best avg r: 0.6324
08:20:55,660 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:22:26,276 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:23:56,865 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1308
en_de Dev loss: 0.9002 r:0.2105
en_zh Dev loss: 0.7766 r:0.4697
ro_en Dev loss: 0.3368 r:0.8154
et_en Dev loss: 0.4454 r:0.6683
si_en Dev loss: 0.8232 r:0.5538
ne_en Dev loss: 0.5515 r:0.7130
ru_en Dev loss: 0.4396 r:0.7320
Current avg r:0.5947 Best avg r: 0.6324
08:28:27,581 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:29:58,207 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:31:28,832 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1348
en_de Dev loss: 0.9013 r:0.2168
en_zh Dev loss: 0.7979 r:0.4609
ro_en Dev loss: 0.3655 r:0.8109
et_en Dev loss: 0.4587 r:0.6517
si_en Dev loss: 0.9255 r:0.5337
ne_en Dev loss: 0.6475 r:0.7105
ru_en Dev loss: 0.4717 r:0.7181
Current avg r:0.5861 Best avg r: 0.6324
08:36:00,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:36:26,496 root INFO 
id:en_zh cur r: 0.4939 best r: 0.4939
08:37:31,624 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:39:02,776 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1345
en_de Dev loss: 0.8991 r:0.2309
en_zh Dev loss: 0.7690 r:0.4829
ro_en Dev loss: 0.3802 r:0.8147
et_en Dev loss: 0.4898 r:0.6594
si_en Dev loss: 0.9183 r:0.5441
ne_en Dev loss: 0.5815 r:0.7089
ru_en Dev loss: 0.4351 r:0.7425
Current avg r:0.5976 Best avg r: 0.6324
08:43:35,48 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:45:06,157 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:46:37,262 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1335
en_de Dev loss: 0.9172 r:0.2065
en_zh Dev loss: 0.8076 r:0.4731
ro_en Dev loss: 0.3618 r:0.8204
et_en Dev loss: 0.5083 r:0.6711
si_en Dev loss: 0.8435 r:0.5499
ne_en Dev loss: 0.5674 r:0.6982
ru_en Dev loss: 0.4550 r:0.7353
Current avg r:0.5935 Best avg r: 0.6324
08:51:09,555 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:51:35,557 root INFO 
id:en_zh cur r: 0.4943 best r: 0.4943
08:52:40,678 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:54:11,862 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1254
en_de Dev loss: 0.9175 r:0.2012
en_zh Dev loss: 0.7605 r:0.4804
ro_en Dev loss: 0.3387 r:0.8192
et_en Dev loss: 0.4746 r:0.6735
si_en Dev loss: 0.8827 r:0.5432
ne_en Dev loss: 0.5439 r:0.7072
ru_en Dev loss: 0.4339 r:0.7433
Current avg r:0.5954 Best avg r: 0.6324
08:58:42,988 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:00:13,609 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:01:44,179 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1317
en_de Dev loss: 0.9212 r:0.1901
en_zh Dev loss: 0.7723 r:0.4800
ro_en Dev loss: 0.3432 r:0.8212
et_en Dev loss: 0.4440 r:0.6805
si_en Dev loss: 0.8614 r:0.5565
ne_en Dev loss: 0.5512 r:0.7119
ru_en Dev loss: 0.4626 r:0.7401
Current avg r:0.5972 Best avg r: 0.6324
09:06:15,298 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:07:45,960 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:09:16,639 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1336
en_de Dev loss: 0.9166 r:0.2025
en_zh Dev loss: 0.7868 r:0.4771
ro_en Dev loss: 0.3543 r:0.8201
et_en Dev loss: 0.4687 r:0.6755
si_en Dev loss: 0.9064 r:0.5469
ne_en Dev loss: 0.5573 r:0.7140
ru_en Dev loss: 0.4605 r:0.7369
Current avg r:0.5961 Best avg r: 0.6324
09:13:47,820 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:15:18,485 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:16:49,150 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1296
en_de Dev loss: 0.9593 r:0.1825
en_zh Dev loss: 0.8448 r:0.4692
ro_en Dev loss: 0.3503 r:0.8212
et_en Dev loss: 0.4631 r:0.6767
si_en Dev loss: 0.8907 r:0.5490
ne_en Dev loss: 0.5679 r:0.7083
ru_en Dev loss: 0.4831 r:0.7367
Current avg r:0.5919 Best avg r: 0.6324
09:21:20,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:22:50,901 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:24:21,550 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1340
en_de Dev loss: 0.9230 r:0.1960
en_zh Dev loss: 0.7504 r:0.4808
ro_en Dev loss: 0.3139 r:0.8219
et_en Dev loss: 0.4647 r:0.6857
si_en Dev loss: 0.8240 r:0.5517
ne_en Dev loss: 0.4996 r:0.7088
ru_en Dev loss: 0.3955 r:0.7619
Current avg r:0.6010 Best avg r: 0.6324
09:28:52,358 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:30:22,990 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:31:53,601 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1324
en_de Dev loss: 0.9037 r:0.2138
en_zh Dev loss: 0.7376 r:0.4855
ro_en Dev loss: 0.3270 r:0.8188
et_en Dev loss: 0.4486 r:0.6786
si_en Dev loss: 0.8611 r:0.5410
ne_en Dev loss: 0.5349 r:0.7082
ru_en Dev loss: 0.4040 r:0.7577
Current avg r:0.6005 Best avg r: 0.6324
09:36:24,240 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:37:54,886 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:39:25,476 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1281
en_de Dev loss: 0.9366 r:0.1950
en_zh Dev loss: 0.8255 r:0.4621
ro_en Dev loss: 0.3873 r:0.8140
et_en Dev loss: 0.4786 r:0.6707
si_en Dev loss: 0.9138 r:0.5414
ne_en Dev loss: 0.6012 r:0.7152
ru_en Dev loss: 0.5039 r:0.7252
Current avg r:0.5891 Best avg r: 0.6324
09:43:57,644 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:45:28,271 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:46:58,909 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1183
en_de Dev loss: 0.9321 r:0.1946
en_zh Dev loss: 0.8075 r:0.4728
ro_en Dev loss: 0.3610 r:0.8166
et_en Dev loss: 0.4752 r:0.6703
si_en Dev loss: 0.9178 r:0.5432
ne_en Dev loss: 0.5704 r:0.7085
ru_en Dev loss: 0.4567 r:0.7430
Current avg r:0.5927 Best avg r: 0.6324
09:51:29,895 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:53:00,600 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:54:31,289 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1194
en_de Dev loss: 0.9327 r:0.2119
en_zh Dev loss: 0.8043 r:0.4748
ro_en Dev loss: 0.3571 r:0.8225
et_en Dev loss: 0.4834 r:0.6782
si_en Dev loss: 0.9227 r:0.5515
ne_en Dev loss: 0.5654 r:0.7137
ru_en Dev loss: 0.4414 r:0.7558
Current avg r:0.6012 Best avg r: 0.6324
09:59:02,389 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:00:33,94 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:02:03,810 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1187
en_de Dev loss: 0.9244 r:0.2055
en_zh Dev loss: 0.7776 r:0.4729
ro_en Dev loss: 0.3693 r:0.8175
et_en Dev loss: 0.4804 r:0.6725
si_en Dev loss: 0.8835 r:0.5479
ne_en Dev loss: 0.6267 r:0.7098
ru_en Dev loss: 0.4504 r:0.7414
Current avg r:0.5953 Best avg r: 0.6324
10:06:34,911 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:08:05,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:09:36,346 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1204
en_de Dev loss: 0.9250 r:0.1944
en_zh Dev loss: 0.7970 r:0.4759
ro_en Dev loss: 0.3618 r:0.8193
et_en Dev loss: 0.4710 r:0.6743
si_en Dev loss: 0.8769 r:0.5479
ne_en Dev loss: 0.5786 r:0.7122
ru_en Dev loss: 0.4640 r:0.7379
Current avg r:0.5946 Best avg r: 0.6324
10:14:07,458 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:15:38,163 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:17:08,895 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1186
en_de Dev loss: 0.9230 r:0.1889
en_zh Dev loss: 0.7658 r:0.4700
ro_en Dev loss: 0.3340 r:0.8175
et_en Dev loss: 0.4595 r:0.6701
si_en Dev loss: 0.8322 r:0.5423
ne_en Dev loss: 0.5149 r:0.7103
ru_en Dev loss: 0.4384 r:0.7400
Current avg r:0.5913 Best avg r: 0.6324
10:21:39,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:23:10,679 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:24:41,418 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1196
en_de Dev loss: 0.9541 r:0.1955
en_zh Dev loss: 0.7971 r:0.4776
ro_en Dev loss: 0.3612 r:0.8178
et_en Dev loss: 0.4739 r:0.6598
si_en Dev loss: 0.8960 r:0.5416
ne_en Dev loss: 0.5767 r:0.7032
ru_en Dev loss: 0.5028 r:0.7277
Current avg r:0.5890 Best avg r: 0.6324
10:29:12,485 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:30:43,208 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
