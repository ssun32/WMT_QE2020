14:56:06,267 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
14:56:19,144 root INFO 
id:en_de cur r: 0.0420 best r: 0.0420
14:56:44,897 root INFO 
id:ro_en cur r: 0.4856 best r: 0.4856
14:57:36,542 root INFO 
id:ru_en cur r: 0.5856 best r: 0.5856
14:57:36,542 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
14:59:06,849 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
14:59:06,858 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
14:59:06,863 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
14:59:06,867 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
14:59:06,872 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
14:59:06,879 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
14:59:06,884 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
14:59:19,816 root INFO Epoch 0 Global steps: 700 Train loss: 0.8561
en_de Dev loss: 0.8876 r:0.0337
en_zh Dev loss: 0.7968 r:0.2064
ro_en Dev loss: 0.7895 r:0.5578
et_en Dev loss: 0.6856 r:0.3950
si_en Dev loss: 0.8230 r:0.4355
ne_en Dev loss: 0.7289 r:0.4668
ru_en Dev loss: 0.6671 r:0.6006
Current avg r:0.3851 Best avg r: 0.3851
15:03:50,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:04:15,803 root INFO 
id:en_zh cur r: 0.1229 best r: 0.1229
15:04:28,742 root INFO 
id:ro_en cur r: 0.6243 best r: 0.6243
15:04:41,696 root INFO 
id:et_en cur r: 0.2885 best r: 0.2885
15:04:54,660 root INFO 
id:si_en cur r: 0.3835 best r: 0.3835
15:05:20,570 root INFO 
id:ne_en cur r: 0.4443 best r: 0.4443
15:05:33,417 root INFO 
id:ru_en cur r: 0.6510 best r: 0.6510
15:05:33,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:07:03,831 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:07:03,839 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:07:03,844 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:07:03,850 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:07:03,855 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:07:03,862 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:07:03,866 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:07:16,818 root INFO Epoch 0 Global steps: 1400 Train loss: 0.8721
en_de Dev loss: 0.9005 r:0.1021
en_zh Dev loss: 0.7995 r:0.2227
ro_en Dev loss: 0.6906 r:0.6945
et_en Dev loss: 0.6097 r:0.4524
si_en Dev loss: 0.8028 r:0.4295
ne_en Dev loss: 0.6440 r:0.5251
ru_en Dev loss: 0.6023 r:0.6520
Current avg r:0.4398 Best avg r: 0.4398
15:11:47,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:12:13,171 root INFO 
id:en_zh cur r: 0.2846 best r: 0.2846
15:12:26,107 root INFO 
id:ro_en cur r: 0.7057 best r: 0.7057
15:12:39,63 root INFO 
id:et_en cur r: 0.6099 best r: 0.6099
15:12:52,24 root INFO 
id:si_en cur r: 0.4786 best r: 0.4786
15:13:17,918 root INFO 
id:ne_en cur r: 0.6173 best r: 0.6173
15:13:30,761 root INFO 
id:ru_en cur r: 0.7083 best r: 0.7083
15:13:30,761 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:15:01,116 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:15:01,123 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:15:01,128 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:15:01,134 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:15:01,140 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:15:01,147 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:15:01,152 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:15:14,82 root INFO Epoch 0 Global steps: 2100 Train loss: 0.7208
en_de Dev loss: 0.9756 r:0.1074
en_zh Dev loss: 0.8188 r:0.2905
ro_en Dev loss: 0.5194 r:0.7241
et_en Dev loss: 0.4488 r:0.6321
si_en Dev loss: 0.6769 r:0.5054
ne_en Dev loss: 0.4754 r:0.6431
ru_en Dev loss: 0.4815 r:0.7089
Current avg r:0.5159 Best avg r: 0.5159
15:19:44,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:19:56,954 root INFO 
id:en_de cur r: 0.1209 best r: 0.1209
15:20:09,851 root INFO 
id:en_zh cur r: 0.3486 best r: 0.3486
15:20:22,773 root INFO 
id:ro_en cur r: 0.7110 best r: 0.7110
15:20:35,714 root INFO 
id:et_en cur r: 0.6267 best r: 0.6267
15:20:48,664 root INFO 
id:si_en cur r: 0.4922 best r: 0.4922
15:21:14,556 root INFO 
id:ne_en cur r: 0.6239 best r: 0.6239
15:21:27,393 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:22:57,729 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:22:57,737 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:22:57,743 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:22:57,749 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:22:57,753 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:22:57,760 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:22:57,766 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:23:10,718 root INFO Epoch 0 Global steps: 2800 Train loss: 0.6438
en_de Dev loss: 0.9735 r:0.1441
en_zh Dev loss: 0.7931 r:0.3599
ro_en Dev loss: 0.5032 r:0.7445
et_en Dev loss: 0.4433 r:0.6545
si_en Dev loss: 0.7405 r:0.5228
ne_en Dev loss: 0.4896 r:0.6409
ru_en Dev loss: 0.4889 r:0.7120
Current avg r:0.5398 Best avg r: 0.5398
15:27:40,749 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:27:53,650 root INFO 
id:en_de cur r: 0.1724 best r: 0.1724
15:28:06,543 root INFO 
id:en_zh cur r: 0.3890 best r: 0.3890
15:28:19,462 root INFO 
id:ro_en cur r: 0.7510 best r: 0.7510
15:28:32,396 root INFO 
id:et_en cur r: 0.6846 best r: 0.6846
15:28:45,337 root INFO 
id:si_en cur r: 0.5415 best r: 0.5415
15:29:11,217 root INFO 
id:ne_en cur r: 0.6750 best r: 0.6750
15:29:24,49 root INFO 
id:ru_en cur r: 0.7151 best r: 0.7151
15:29:24,49 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:30:54,334 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:30:54,340 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:30:54,346 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:30:54,351 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:30:54,356 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:30:54,363 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:30:54,368 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:31:07,300 root INFO Epoch 0 Global steps: 3500 Train loss: 0.6592
en_de Dev loss: 1.0347 r:0.1692
en_zh Dev loss: 0.9240 r:0.3878
ro_en Dev loss: 0.5059 r:0.7659
et_en Dev loss: 0.4062 r:0.6945
si_en Dev loss: 0.8031 r:0.5532
ne_en Dev loss: 0.5109 r:0.6708
ru_en Dev loss: 0.5523 r:0.7263
Current avg r:0.5668 Best avg r: 0.5668
15:35:37,381 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:36:16,83 root INFO 
id:ro_en cur r: 0.7656 best r: 0.7656
15:36:41,972 root INFO 
id:si_en cur r: 0.5422 best r: 0.5422
15:37:07,847 root INFO 
id:ne_en cur r: 0.6781 best r: 0.6781
15:37:20,687 root INFO 
id:ru_en cur r: 0.7163 best r: 0.7163
15:37:20,687 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:38:50,983 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:38:50,990 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:38:50,995 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:38:51,0 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:38:51,5 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:38:51,11 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:38:51,17 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:39:03,945 root INFO Epoch 0 Global steps: 4200 Train loss: 0.5774
en_de Dev loss: 0.9860 r:0.1626
en_zh Dev loss: 0.8267 r:0.3854
ro_en Dev loss: 0.4250 r:0.7805
et_en Dev loss: 0.3834 r:0.6926
si_en Dev loss: 0.7136 r:0.5589
ne_en Dev loss: 0.4499 r:0.6850
ru_en Dev loss: 0.4884 r:0.7280
Current avg r:0.5704 Best avg r: 0.5704
15:43:34,12 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:43:46,902 root INFO 
id:en_de cur r: 0.2003 best r: 0.2003
15:43:59,781 root INFO 
id:en_zh cur r: 0.4210 best r: 0.4210
15:44:12,703 root INFO 
id:ro_en cur r: 0.7737 best r: 0.7737
15:44:38,602 root INFO 
id:si_en cur r: 0.5712 best r: 0.5712
15:45:04,498 root INFO 
id:ne_en cur r: 0.6979 best r: 0.6979
15:45:17,319 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:46:47,700 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:46:47,709 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:46:47,714 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:46:47,719 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:46:47,725 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:46:47,733 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:46:47,739 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:47:00,689 root INFO Epoch 0 Global steps: 4900 Train loss: 0.6085
en_de Dev loss: 0.8709 r:0.1896
en_zh Dev loss: 0.6850 r:0.4250
ro_en Dev loss: 0.3628 r:0.7866
et_en Dev loss: 0.3610 r:0.7010
si_en Dev loss: 0.6478 r:0.5848
ne_en Dev loss: 0.4805 r:0.6952
ru_en Dev loss: 0.4918 r:0.7251
Current avg r:0.5867 Best avg r: 0.5867
15:51:31,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:51:57,104 root INFO 
id:en_zh cur r: 0.4268 best r: 0.4268
15:52:10,5 root INFO 
id:ro_en cur r: 0.7895 best r: 0.7895
15:52:22,947 root INFO 
id:et_en cur r: 0.6904 best r: 0.6904
15:52:35,889 root INFO 
id:si_en cur r: 0.5882 best r: 0.5882
15:53:01,791 root INFO 
id:ne_en cur r: 0.7127 best r: 0.7127
15:53:14,629 root INFO 
id:ru_en cur r: 0.7298 best r: 0.7298
15:53:14,630 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
15:54:44,940 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
15:54:44,946 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
15:54:44,951 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
15:54:44,956 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
15:54:44,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
15:54:44,966 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
15:54:44,971 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
15:54:57,911 root INFO Epoch 0 Global steps: 5600 Train loss: 0.5584
en_de Dev loss: 0.9374 r:0.1834
en_zh Dev loss: 0.7286 r:0.4371
ro_en Dev loss: 0.3427 r:0.7987
et_en Dev loss: 0.3584 r:0.7079
si_en Dev loss: 0.6539 r:0.6028
ne_en Dev loss: 0.4332 r:0.7121
ru_en Dev loss: 0.4476 r:0.7463
Current avg r:0.5983 Best avg r: 0.5983
15:59:28,175 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
15:59:53,953 root INFO 
id:en_zh cur r: 0.4321 best r: 0.4321
16:00:06,860 root INFO 
id:ro_en cur r: 0.7951 best r: 0.7951
16:00:19,802 root INFO 
id:et_en cur r: 0.7016 best r: 0.7016
16:00:32,738 root INFO 
id:si_en cur r: 0.5952 best r: 0.5952
16:00:58,618 root INFO 
id:ne_en cur r: 0.7327 best r: 0.7327
16:01:11,460 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:02:41,801 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:02:41,808 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:02:41,813 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:02:41,818 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:02:41,822 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:02:41,828 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:02:41,833 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:02:54,768 root INFO Epoch 0 Global steps: 6300 Train loss: 0.5672
en_de Dev loss: 0.9332 r:0.1904
en_zh Dev loss: 0.7659 r:0.4330
ro_en Dev loss: 0.3599 r:0.7990
et_en Dev loss: 0.3643 r:0.7144
si_en Dev loss: 0.7409 r:0.6031
ne_en Dev loss: 0.4227 r:0.7286
ru_en Dev loss: 0.4990 r:0.7406
Current avg r:0.6013 Best avg r: 0.6013
16:07:25,287 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:07:38,174 root INFO 
id:en_de cur r: 0.2103 best r: 0.2103
16:07:51,61 root INFO 
id:en_zh cur r: 0.4374 best r: 0.4374
16:08:16,894 root INFO 
id:et_en cur r: 0.7047 best r: 0.7047
16:08:55,589 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:10:25,875 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:10:25,882 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:10:25,887 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:10:25,892 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:10:25,897 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:10:25,906 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:10:25,911 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:10:38,851 root INFO Epoch 0 Global steps: 7000 Train loss: 0.5688
en_de Dev loss: 0.9015 r:0.2118
en_zh Dev loss: 0.7148 r:0.4415
ro_en Dev loss: 0.3726 r:0.7968
et_en Dev loss: 0.3742 r:0.7141
si_en Dev loss: 0.7272 r:0.5964
ne_en Dev loss: 0.4795 r:0.7227
ru_en Dev loss: 0.4904 r:0.7423
Current avg r:0.6037 Best avg r: 0.6037
16:15:08,899 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:15:21,797 root INFO 
id:en_de cur r: 0.2300 best r: 0.2300
16:15:34,694 root INFO 
id:en_zh cur r: 0.4412 best r: 0.4412
16:15:47,616 root INFO 
id:ro_en cur r: 0.8052 best r: 0.8052
16:16:00,549 root INFO 
id:et_en cur r: 0.7074 best r: 0.7074
16:16:39,383 root INFO 
id:ne_en cur r: 0.7396 best r: 0.7396
16:16:52,211 root INFO 
id:ru_en cur r: 0.7331 best r: 0.7331
16:16:52,212 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:18:22,536 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:18:22,543 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:18:22,552 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:18:22,558 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:18:22,564 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:18:22,569 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:18:22,575 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:18:35,516 root INFO Epoch 0 Global steps: 7700 Train loss: 0.5328
en_de Dev loss: 0.8873 r:0.2135
en_zh Dev loss: 0.7397 r:0.4482
ro_en Dev loss: 0.3346 r:0.8063
et_en Dev loss: 0.3542 r:0.7174
si_en Dev loss: 0.6953 r:0.6023
ne_en Dev loss: 0.4339 r:0.7366
ru_en Dev loss: 0.4779 r:0.7456
Current avg r:0.6100 Best avg r: 0.6100
16:23:05,600 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:23:31,406 root INFO 
id:en_zh cur r: 0.4475 best r: 0.4475
16:24:35,968 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:26:06,284 root INFO Epoch 0 Global steps: 8400 Train loss: 0.5427
en_de Dev loss: 0.9322 r:0.2113
en_zh Dev loss: 0.7742 r:0.4567
ro_en Dev loss: 0.3649 r:0.8087
et_en Dev loss: 0.3683 r:0.7150
si_en Dev loss: 0.7536 r:0.6028
ne_en Dev loss: 0.4578 r:0.7341
ru_en Dev loss: 0.5435 r:0.7277
Current avg r:0.6080 Best avg r: 0.6100
16:30:36,310 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:30:49,216 root INFO 
id:en_de cur r: 0.2307 best r: 0.2307
16:31:02,110 root INFO 
id:en_zh cur r: 0.4724 best r: 0.4724
16:31:27,941 root INFO 
id:et_en cur r: 0.7120 best r: 0.7120
16:31:40,880 root INFO 
id:si_en cur r: 0.6078 best r: 0.6078
16:32:06,626 root INFO 
id:ru_en cur r: 0.7360 best r: 0.7360
16:32:06,627 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:33:36,915 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:33:36,923 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:33:36,927 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:33:36,932 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:33:36,937 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:33:36,943 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:33:36,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:33:49,868 root INFO Epoch 0 Global steps: 9100 Train loss: 0.5526
en_de Dev loss: 0.8628 r:0.2231
en_zh Dev loss: 0.6508 r:0.4785
ro_en Dev loss: 0.3190 r:0.8078
et_en Dev loss: 0.3420 r:0.7211
si_en Dev loss: 0.6443 r:0.6169
ne_en Dev loss: 0.4513 r:0.7352
ru_en Dev loss: 0.4306 r:0.7474
Current avg r:0.6186 Best avg r: 0.6186
16:38:19,906 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:38:58,563 root INFO 
id:ro_en cur r: 0.8125 best r: 0.8125
16:39:11,490 root INFO 
id:et_en cur r: 0.7146 best r: 0.7146
16:39:24,435 root INFO 
id:si_en cur r: 0.6138 best r: 0.6138
16:39:50,310 root INFO 
id:ne_en cur r: 0.7534 best r: 0.7534
16:40:03,144 root INFO 
id:ru_en cur r: 0.7408 best r: 0.7408
16:40:03,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:41:33,441 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:41:33,448 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:41:33,453 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:41:33,458 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:41:33,463 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:41:33,468 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:41:33,473 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:41:46,407 root INFO Epoch 0 Global steps: 9800 Train loss: 0.5175
en_de Dev loss: 0.8605 r:0.2120
en_zh Dev loss: 0.6499 r:0.4783
ro_en Dev loss: 0.3048 r:0.8112
et_en Dev loss: 0.3575 r:0.7201
si_en Dev loss: 0.5632 r:0.6174
ne_en Dev loss: 0.3686 r:0.7522
ru_en Dev loss: 0.3859 r:0.7511
Current avg r:0.6203 Best avg r: 0.6203
16:46:16,505 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:46:55,151 root INFO 
id:ro_en cur r: 0.8134 best r: 0.8134
16:47:46,880 root INFO 
id:ne_en cur r: 0.7578 best r: 0.7578
16:47:59,701 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:49:30,24 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
16:49:30,34 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
16:49:30,40 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
16:49:30,46 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
16:49:30,53 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
16:49:30,60 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
16:49:30,66 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
16:49:43,31 root INFO Epoch 0 Global steps: 10500 Train loss: 0.5514
en_de Dev loss: 0.8579 r:0.2155
en_zh Dev loss: 0.6686 r:0.4754
ro_en Dev loss: 0.2975 r:0.8174
et_en Dev loss: 0.3376 r:0.7232
si_en Dev loss: 0.5673 r:0.6122
ne_en Dev loss: 0.3671 r:0.7550
ru_en Dev loss: 0.4026 r:0.7475
Current avg r:0.6209 Best avg r: 0.6209
16:54:14,837 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
16:54:27,754 root INFO 
id:en_de cur r: 0.2311 best r: 0.2311
16:54:53,562 root INFO 
id:ro_en cur r: 0.8140 best r: 0.8140
16:55:45,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
16:57:15,482 root INFO Epoch 1 Global steps: 11200 Train loss: 0.4796
en_de Dev loss: 0.8573 r:0.2251
en_zh Dev loss: 0.7023 r:0.4664
ro_en Dev loss: 0.3264 r:0.8133
et_en Dev loss: 0.3607 r:0.7125
si_en Dev loss: 0.6603 r:0.6030
ne_en Dev loss: 0.4961 r:0.7472
ru_en Dev loss: 0.5024 r:0.7227
Current avg r:0.6129 Best avg r: 0.6209
17:01:45,637 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:03:15,949 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:04:46,211 root INFO Epoch 1 Global steps: 11900 Train loss: 0.4954
en_de Dev loss: 0.9390 r:0.2040
en_zh Dev loss: 0.9152 r:0.4435
ro_en Dev loss: 0.4478 r:0.8005
et_en Dev loss: 0.4402 r:0.7015
si_en Dev loss: 0.9054 r:0.5830
ne_en Dev loss: 0.5731 r:0.7422
ru_en Dev loss: 0.6318 r:0.7002
Current avg r:0.5964 Best avg r: 0.6209
17:09:16,663 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:09:55,376 root INFO 
id:ro_en cur r: 0.8188 best r: 0.8188
17:10:47,56 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:12:17,443 root INFO Epoch 1 Global steps: 12600 Train loss: 0.4817
en_de Dev loss: 0.8569 r:0.2230
en_zh Dev loss: 0.7075 r:0.4654
ro_en Dev loss: 0.3130 r:0.8145
et_en Dev loss: 0.3656 r:0.7151
si_en Dev loss: 0.6250 r:0.6123
ne_en Dev loss: 0.3845 r:0.7552
ru_en Dev loss: 0.4255 r:0.7404
Current avg r:0.6180 Best avg r: 0.6209
17:16:48,74 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:17:13,871 root INFO 
id:en_zh cur r: 0.4780 best r: 0.4780
17:17:26,788 root INFO 
id:ro_en cur r: 0.8225 best r: 0.8225
17:18:18,428 root INFO 
id:ru_en cur r: 0.7620 best r: 0.7620
17:18:18,429 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:19:48,690 root INFO Epoch 1 Global steps: 13300 Train loss: 0.4865
en_de Dev loss: 0.8597 r:0.2098
en_zh Dev loss: 0.6899 r:0.4825
ro_en Dev loss: 0.3363 r:0.8177
et_en Dev loss: 0.3621 r:0.7142
si_en Dev loss: 0.7496 r:0.6083
ne_en Dev loss: 0.4832 r:0.7531
ru_en Dev loss: 0.4214 r:0.7585
Current avg r:0.6206 Best avg r: 0.6209
17:24:18,944 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:25:49,256 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:27:19,572 root INFO Epoch 1 Global steps: 14000 Train loss: 0.4880
en_de Dev loss: 0.8920 r:0.2125
en_zh Dev loss: 0.7925 r:0.4666
ro_en Dev loss: 0.4013 r:0.8183
et_en Dev loss: 0.3810 r:0.7174
si_en Dev loss: 0.7949 r:0.6035
ne_en Dev loss: 0.5560 r:0.7548
ru_en Dev loss: 0.5385 r:0.7297
Current avg r:0.6147 Best avg r: 0.6209
17:31:49,859 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:32:02,753 root INFO 
id:en_de cur r: 0.2380 best r: 0.2380
17:32:28,549 root INFO 
id:ro_en cur r: 0.8256 best r: 0.8256
17:33:20,167 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:34:50,479 root INFO Epoch 1 Global steps: 14700 Train loss: 0.5135
en_de Dev loss: 0.8645 r:0.2288
en_zh Dev loss: 0.7036 r:0.4708
ro_en Dev loss: 0.3510 r:0.8200
et_en Dev loss: 0.3694 r:0.7161
si_en Dev loss: 0.7061 r:0.6081
ne_en Dev loss: 0.4894 r:0.7508
ru_en Dev loss: 0.4534 r:0.7350
Current avg r:0.6185 Best avg r: 0.6209
17:39:20,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:40:51,98 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:42:21,420 root INFO Epoch 1 Global steps: 15400 Train loss: 0.5077
en_de Dev loss: 0.8490 r:0.2267
en_zh Dev loss: 0.7181 r:0.4768
ro_en Dev loss: 0.3269 r:0.8203
et_en Dev loss: 0.3553 r:0.7182
si_en Dev loss: 0.7644 r:0.6056
ne_en Dev loss: 0.5746 r:0.7371
ru_en Dev loss: 0.4931 r:0.7198
Current avg r:0.6149 Best avg r: 0.6209
17:46:51,695 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:47:30,401 root INFO 
id:ro_en cur r: 0.8277 best r: 0.8277
17:47:43,340 root INFO 
id:et_en cur r: 0.7176 best r: 0.7176
17:47:56,289 root INFO 
id:si_en cur r: 0.6145 best r: 0.6145
17:48:22,75 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:49:52,398 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
17:49:52,406 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
17:49:52,411 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
17:49:52,416 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
17:49:52,420 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
17:49:52,426 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
17:49:52,431 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
17:50:05,366 root INFO Epoch 1 Global steps: 16100 Train loss: 0.4716
en_de Dev loss: 0.8547 r:0.2286
en_zh Dev loss: 0.7032 r:0.4730
ro_en Dev loss: 0.3146 r:0.8231
et_en Dev loss: 0.3512 r:0.7242
si_en Dev loss: 0.6546 r:0.6166
ne_en Dev loss: 0.3987 r:0.7558
ru_en Dev loss: 0.4400 r:0.7424
Current avg r:0.6234 Best avg r: 0.6234
17:54:35,942 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
17:54:48,848 root INFO 
id:en_de cur r: 0.2444 best r: 0.2444
17:55:01,747 root INFO 
id:en_zh cur r: 0.4785 best r: 0.4785
17:56:06,373 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
17:57:36,725 root INFO Epoch 1 Global steps: 16800 Train loss: 0.4767
en_de Dev loss: 0.8685 r:0.2371
en_zh Dev loss: 0.7135 r:0.4775
ro_en Dev loss: 0.3485 r:0.8166
et_en Dev loss: 0.3715 r:0.7156
si_en Dev loss: 0.7298 r:0.6058
ne_en Dev loss: 0.5166 r:0.7514
ru_en Dev loss: 0.4732 r:0.7286
Current avg r:0.6189 Best avg r: 0.6234
18:02:07,236 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:03:37,732 root INFO 
id:ne_en cur r: 0.7581 best r: 0.7581
18:03:50,577 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:05:20,961 root INFO Epoch 1 Global steps: 17500 Train loss: 0.4894
en_de Dev loss: 0.8538 r:0.2374
en_zh Dev loss: 0.7362 r:0.4694
ro_en Dev loss: 0.3455 r:0.8165
et_en Dev loss: 0.3711 r:0.7161
si_en Dev loss: 0.7147 r:0.6060
ne_en Dev loss: 0.4425 r:0.7572
ru_en Dev loss: 0.4648 r:0.7200
Current avg r:0.6175 Best avg r: 0.6234
18:09:51,374 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:10:04,278 root INFO 
id:en_de cur r: 0.2615 best r: 0.2615
18:10:17,153 root INFO 
id:en_zh cur r: 0.4904 best r: 0.4904
18:10:30,59 root INFO 
id:ro_en cur r: 0.8285 best r: 0.8285
18:10:42,998 root INFO 
id:et_en cur r: 0.7183 best r: 0.7183
18:11:21,802 root INFO 
id:ne_en cur r: 0.7633 best r: 0.7633
18:11:34,621 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:13:04,948 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:13:04,955 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:13:04,960 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:13:04,965 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:13:04,970 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:13:04,977 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:13:04,981 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:13:17,921 root INFO Epoch 1 Global steps: 18200 Train loss: 0.4635
en_de Dev loss: 0.8313 r:0.2548
en_zh Dev loss: 0.6430 r:0.4883
ro_en Dev loss: 0.2938 r:0.8222
et_en Dev loss: 0.3611 r:0.7216
si_en Dev loss: 0.6476 r:0.6156
ne_en Dev loss: 0.3734 r:0.7639
ru_en Dev loss: 0.3726 r:0.7588
Current avg r:0.6322 Best avg r: 0.6322
18:17:48,44 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:18:13,819 root INFO 
id:en_zh cur r: 0.4932 best r: 0.4932
18:18:52,608 root INFO 
id:si_en cur r: 0.6165 best r: 0.6165
18:19:18,376 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:20:48,693 root INFO Epoch 1 Global steps: 18900 Train loss: 0.4703
en_de Dev loss: 0.8424 r:0.2333
en_zh Dev loss: 0.6481 r:0.4881
ro_en Dev loss: 0.2947 r:0.8267
et_en Dev loss: 0.3476 r:0.7196
si_en Dev loss: 0.6339 r:0.6209
ne_en Dev loss: 0.3842 r:0.7649
ru_en Dev loss: 0.4340 r:0.7412
Current avg r:0.6278 Best avg r: 0.6322
18:25:18,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:25:44,787 root INFO 
id:en_zh cur r: 0.5089 best r: 0.5089
18:25:57,709 root INFO 
id:ro_en cur r: 0.8314 best r: 0.8314
18:26:10,653 root INFO 
id:et_en cur r: 0.7199 best r: 0.7199
18:26:23,599 root INFO 
id:si_en cur r: 0.6253 best r: 0.6253
18:26:49,484 root INFO 
id:ne_en cur r: 0.7721 best r: 0.7721
18:27:02,328 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:28:32,632 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_de.lang_agnost_mlp.dev.best.scores
18:28:32,640 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/en_zh.lang_agnost_mlp.dev.best.scores
18:28:32,645 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ro_en.lang_agnost_mlp.dev.best.scores
18:28:32,650 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/et_en.lang_agnost_mlp.dev.best.scores
18:28:32,654 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/si_en.lang_agnost_mlp.dev.best.scores
18:28:32,662 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ne_en.lang_agnost_mlp.dev.best.scores
18:28:32,666 root INFO Saving best dev results to: experiments_xlmr/H1.2/mtl_fewshot_1.0_neen/run4/ru_en.lang_agnost_mlp.dev.best.scores
18:28:45,616 root INFO Epoch 1 Global steps: 19600 Train loss: 0.4767
en_de Dev loss: 0.8344 r:0.2543
en_zh Dev loss: 0.6615 r:0.5058
ro_en Dev loss: 0.3129 r:0.8275
et_en Dev loss: 0.3611 r:0.7235
si_en Dev loss: 0.5953 r:0.6266
ne_en Dev loss: 0.3714 r:0.7724
ru_en Dev loss: 0.4255 r:0.7580
Current avg r:0.6383 Best avg r: 0.6383
18:33:15,846 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:33:54,512 root INFO 
id:ro_en cur r: 0.8328 best r: 0.8328
18:34:07,439 root INFO 
id:et_en cur r: 0.7208 best r: 0.7208
18:34:46,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:36:16,437 root INFO Epoch 1 Global steps: 20300 Train loss: 0.4768
en_de Dev loss: 0.8263 r:0.2646
en_zh Dev loss: 0.6528 r:0.4965
ro_en Dev loss: 0.3009 r:0.8302
et_en Dev loss: 0.3582 r:0.7244
si_en Dev loss: 0.6496 r:0.6207
ne_en Dev loss: 0.3974 r:0.7631
ru_en Dev loss: 0.4299 r:0.7497
Current avg r:0.6356 Best avg r: 0.6383
18:40:47,205 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:42:17,481 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:43:47,852 root INFO Epoch 1 Global steps: 21000 Train loss: 0.4607
en_de Dev loss: 0.8502 r:0.2445
en_zh Dev loss: 0.7830 r:0.4817
ro_en Dev loss: 0.3314 r:0.8239
et_en Dev loss: 0.3736 r:0.7189
si_en Dev loss: 0.8192 r:0.6111
ne_en Dev loss: 0.5086 r:0.7642
ru_en Dev loss: 0.4511 r:0.7450
Current avg r:0.6270 Best avg r: 0.6383
18:48:19,344 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:49:49,657 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:51:19,974 root INFO Epoch 2 Global steps: 21700 Train loss: 0.4470
en_de Dev loss: 0.8441 r:0.2475
en_zh Dev loss: 0.7040 r:0.4865
ro_en Dev loss: 0.3353 r:0.8201
et_en Dev loss: 0.3744 r:0.7149
si_en Dev loss: 0.7780 r:0.6094
ne_en Dev loss: 0.3813 r:0.7608
ru_en Dev loss: 0.4337 r:0.7350
Current avg r:0.6249 Best avg r: 0.6383
18:55:50,157 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
18:56:03,46 root INFO 
id:en_de cur r: 0.2702 best r: 0.2702
18:57:20,450 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
18:58:50,732 root INFO Epoch 2 Global steps: 22400 Train loss: 0.4294
en_de Dev loss: 0.8271 r:0.2691
en_zh Dev loss: 0.6632 r:0.4840
ro_en Dev loss: 0.3034 r:0.8184
et_en Dev loss: 0.3535 r:0.7119
si_en Dev loss: 0.7823 r:0.6008
ne_en Dev loss: 0.4745 r:0.7545
ru_en Dev loss: 0.4405 r:0.7302
Current avg r:0.6241 Best avg r: 0.6383
19:03:20,813 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:04:51,55 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:06:21,322 root INFO Epoch 2 Global steps: 23100 Train loss: 0.4545
en_de Dev loss: 0.8427 r:0.2545
en_zh Dev loss: 0.7083 r:0.4831
ro_en Dev loss: 0.3617 r:0.8185
et_en Dev loss: 0.3873 r:0.7105
si_en Dev loss: 0.8379 r:0.6041
ne_en Dev loss: 0.5147 r:0.7534
ru_en Dev loss: 0.4878 r:0.7299
Current avg r:0.6220 Best avg r: 0.6383
19:10:51,414 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:12:21,676 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:13:51,996 root INFO Epoch 2 Global steps: 23800 Train loss: 0.4442
en_de Dev loss: 0.8328 r:0.2614
en_zh Dev loss: 0.6724 r:0.4854
ro_en Dev loss: 0.3149 r:0.8218
et_en Dev loss: 0.3612 r:0.7127
si_en Dev loss: 0.7003 r:0.6033
ne_en Dev loss: 0.4443 r:0.7499
ru_en Dev loss: 0.4632 r:0.7209
Current avg r:0.6222 Best avg r: 0.6383
19:18:22,127 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:19:52,434 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:21:22,752 root INFO Epoch 2 Global steps: 24500 Train loss: 0.4233
en_de Dev loss: 0.8748 r:0.2310
en_zh Dev loss: 0.7284 r:0.4830
ro_en Dev loss: 0.3365 r:0.8271
et_en Dev loss: 0.4103 r:0.7113
si_en Dev loss: 0.6920 r:0.6170
ne_en Dev loss: 0.3876 r:0.7547
ru_en Dev loss: 0.4491 r:0.7373
Current avg r:0.6231 Best avg r: 0.6383
19:25:52,841 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:27:23,130 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:28:53,444 root INFO Epoch 2 Global steps: 25200 Train loss: 0.4164
en_de Dev loss: 0.8279 r:0.2589
en_zh Dev loss: 0.6599 r:0.4957
ro_en Dev loss: 0.3065 r:0.8284
et_en Dev loss: 0.3715 r:0.7148
si_en Dev loss: 0.6400 r:0.6232
ne_en Dev loss: 0.3618 r:0.7591
ru_en Dev loss: 0.4014 r:0.7487
Current avg r:0.6327 Best avg r: 0.6383
19:33:23,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:34:53,835 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:36:24,85 root INFO Epoch 2 Global steps: 25900 Train loss: 0.4192
en_de Dev loss: 0.8563 r:0.2344
en_zh Dev loss: 0.7574 r:0.4755
ro_en Dev loss: 0.3244 r:0.8246
et_en Dev loss: 0.3828 r:0.7055
si_en Dev loss: 0.7330 r:0.6054
ne_en Dev loss: 0.3920 r:0.7524
ru_en Dev loss: 0.4582 r:0.7266
Current avg r:0.6178 Best avg r: 0.6383
19:40:54,166 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:42:24,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:43:54,761 root INFO Epoch 2 Global steps: 26600 Train loss: 0.4201
en_de Dev loss: 0.8583 r:0.2304
en_zh Dev loss: 0.7488 r:0.4766
ro_en Dev loss: 0.3485 r:0.8275
et_en Dev loss: 0.3852 r:0.7112
si_en Dev loss: 0.7561 r:0.6063
ne_en Dev loss: 0.4142 r:0.7597
ru_en Dev loss: 0.4578 r:0.7406
Current avg r:0.6217 Best avg r: 0.6383
19:48:24,819 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:49:03,526 root INFO 
id:ro_en cur r: 0.8335 best r: 0.8335
19:49:55,183 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:51:25,512 root INFO Epoch 2 Global steps: 27300 Train loss: 0.4046
en_de Dev loss: 0.8352 r:0.2482
en_zh Dev loss: 0.6931 r:0.4936
ro_en Dev loss: 0.3298 r:0.8275
et_en Dev loss: 0.4027 r:0.7077
si_en Dev loss: 0.7531 r:0.6073
ne_en Dev loss: 0.4734 r:0.7529
ru_en Dev loss: 0.4970 r:0.7175
Current avg r:0.6221 Best avg r: 0.6383
19:55:55,610 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
19:57:25,957 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
19:58:56,273 root INFO Epoch 2 Global steps: 28000 Train loss: 0.4257
en_de Dev loss: 0.8402 r:0.2448
en_zh Dev loss: 0.7020 r:0.4957
ro_en Dev loss: 0.3498 r:0.8247
et_en Dev loss: 0.4038 r:0.7015
si_en Dev loss: 0.7152 r:0.6082
ne_en Dev loss: 0.4094 r:0.7533
ru_en Dev loss: 0.4825 r:0.7318
Current avg r:0.6229 Best avg r: 0.6383
20:03:26,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:04:56,742 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:06:27,25 root INFO Epoch 2 Global steps: 28700 Train loss: 0.4047
en_de Dev loss: 0.8375 r:0.2471
en_zh Dev loss: 0.7152 r:0.4873
ro_en Dev loss: 0.3415 r:0.8268
et_en Dev loss: 0.4349 r:0.7099
si_en Dev loss: 0.5886 r:0.6202
ne_en Dev loss: 0.3770 r:0.7579
ru_en Dev loss: 0.4426 r:0.7357
Current avg r:0.6264 Best avg r: 0.6383
20:10:57,93 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:11:35,743 root INFO 
id:ro_en cur r: 0.8344 best r: 0.8344
20:12:01,614 root INFO 
id:si_en cur r: 0.6276 best r: 0.6276
20:12:27,357 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:13:57,679 root INFO Epoch 2 Global steps: 29400 Train loss: 0.4213
en_de Dev loss: 0.8435 r:0.2358
en_zh Dev loss: 0.7072 r:0.4938
ro_en Dev loss: 0.3159 r:0.8316
et_en Dev loss: 0.3963 r:0.7086
si_en Dev loss: 0.6457 r:0.6251
ne_en Dev loss: 0.3752 r:0.7611
ru_en Dev loss: 0.4217 r:0.7454
Current avg r:0.6288 Best avg r: 0.6383
20:18:27,653 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:19:57,954 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:21:28,277 root INFO Epoch 2 Global steps: 30100 Train loss: 0.4071
en_de Dev loss: 0.8511 r:0.2459
en_zh Dev loss: 0.6946 r:0.4844
ro_en Dev loss: 0.3170 r:0.8295
et_en Dev loss: 0.3797 r:0.7084
si_en Dev loss: 0.6497 r:0.6163
ne_en Dev loss: 0.4079 r:0.7607
ru_en Dev loss: 0.4305 r:0.7344
Current avg r:0.6256 Best avg r: 0.6383
20:25:58,245 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:27:02,805 root INFO 
id:si_en cur r: 0.6282 best r: 0.6282
20:27:28,570 root INFO 
id:ru_en cur r: 0.7632 best r: 0.7632
20:27:28,571 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:28:58,822 root INFO Epoch 2 Global steps: 30800 Train loss: 0.4181
en_de Dev loss: 0.8393 r:0.2541
en_zh Dev loss: 0.6761 r:0.5003
ro_en Dev loss: 0.3244 r:0.8300
et_en Dev loss: 0.3961 r:0.7149
si_en Dev loss: 0.5932 r:0.6265
ne_en Dev loss: 0.4039 r:0.7600
ru_en Dev loss: 0.3960 r:0.7592
Current avg r:0.6350 Best avg r: 0.6383
20:33:28,836 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:34:07,505 root INFO 
id:ro_en cur r: 0.8348 best r: 0.8348
20:34:59,117 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:36:29,408 root INFO Epoch 2 Global steps: 31500 Train loss: 0.3904
en_de Dev loss: 0.8431 r:0.2475
en_zh Dev loss: 0.7306 r:0.4798
ro_en Dev loss: 0.3198 r:0.8311
et_en Dev loss: 0.3946 r:0.7055
si_en Dev loss: 0.6278 r:0.6202
ne_en Dev loss: 0.3617 r:0.7618
ru_en Dev loss: 0.4155 r:0.7458
Current avg r:0.6274 Best avg r: 0.6383
20:41:00,981 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:42:31,286 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:44:01,642 root INFO Epoch 3 Global steps: 32200 Train loss: 0.3863
en_de Dev loss: 0.8504 r:0.2338
en_zh Dev loss: 0.7540 r:0.4681
ro_en Dev loss: 0.3322 r:0.8262
et_en Dev loss: 0.3947 r:0.6994
si_en Dev loss: 0.8201 r:0.5945
ne_en Dev loss: 0.5301 r:0.7506
ru_en Dev loss: 0.4568 r:0.7246
Current avg r:0.6139 Best avg r: 0.6383
20:48:32,114 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:50:02,453 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:51:32,770 root INFO Epoch 3 Global steps: 32900 Train loss: 0.3739
en_de Dev loss: 0.8720 r:0.2404
en_zh Dev loss: 0.7479 r:0.4736
ro_en Dev loss: 0.3576 r:0.8255
et_en Dev loss: 0.4109 r:0.7004
si_en Dev loss: 0.7679 r:0.6009
ne_en Dev loss: 0.4699 r:0.7596
ru_en Dev loss: 0.4972 r:0.7167
Current avg r:0.6167 Best avg r: 0.6383
20:56:02,843 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
20:57:33,161 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
20:59:03,465 root INFO Epoch 3 Global steps: 33600 Train loss: 0.3519
en_de Dev loss: 0.8609 r:0.2140
en_zh Dev loss: 0.7364 r:0.4781
ro_en Dev loss: 0.3861 r:0.8211
et_en Dev loss: 0.4301 r:0.6940
si_en Dev loss: 0.8569 r:0.5941
ne_en Dev loss: 0.5021 r:0.7557
ru_en Dev loss: 0.5482 r:0.6976
Current avg r:0.6078 Best avg r: 0.6383
21:03:33,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:05:03,763 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:06:34,81 root INFO Epoch 3 Global steps: 34300 Train loss: 0.3647
en_de Dev loss: 0.8608 r:0.2273
en_zh Dev loss: 0.7209 r:0.4918
ro_en Dev loss: 0.3881 r:0.8253
et_en Dev loss: 0.4407 r:0.6969
si_en Dev loss: 0.8997 r:0.6024
ne_en Dev loss: 0.5300 r:0.7563
ru_en Dev loss: 0.5337 r:0.7175
Current avg r:0.6168 Best avg r: 0.6383
21:11:04,518 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:12:34,917 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:14:05,345 root INFO Epoch 3 Global steps: 35000 Train loss: 0.3460
en_de Dev loss: 0.8531 r:0.2093
en_zh Dev loss: 0.7031 r:0.4703
ro_en Dev loss: 0.3128 r:0.8264
et_en Dev loss: 0.3964 r:0.7007
si_en Dev loss: 0.7587 r:0.6060
ne_en Dev loss: 0.4780 r:0.7498
ru_en Dev loss: 0.4790 r:0.7129
Current avg r:0.6108 Best avg r: 0.6383
21:18:36,9 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:20:06,382 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:21:36,764 root INFO Epoch 3 Global steps: 35700 Train loss: 0.3627
en_de Dev loss: 0.8460 r:0.2394
en_zh Dev loss: 0.6873 r:0.4916
ro_en Dev loss: 0.3283 r:0.8277
et_en Dev loss: 0.4676 r:0.7109
si_en Dev loss: 0.6263 r:0.6205
ne_en Dev loss: 0.3782 r:0.7439
ru_en Dev loss: 0.4128 r:0.7471
Current avg r:0.6259 Best avg r: 0.6383
21:26:07,103 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:27:37,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:29:07,779 root INFO Epoch 3 Global steps: 36400 Train loss: 0.3602
en_de Dev loss: 0.8485 r:0.2409
en_zh Dev loss: 0.6744 r:0.4949
ro_en Dev loss: 0.3247 r:0.8227
et_en Dev loss: 0.4192 r:0.7053
si_en Dev loss: 0.6870 r:0.6084
ne_en Dev loss: 0.3948 r:0.7350
ru_en Dev loss: 0.4166 r:0.7463
Current avg r:0.6219 Best avg r: 0.6383
21:33:38,11 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:35:08,302 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:36:38,609 root INFO Epoch 3 Global steps: 37100 Train loss: 0.3600
en_de Dev loss: 0.8898 r:0.2529
en_zh Dev loss: 0.7567 r:0.4785
ro_en Dev loss: 0.3574 r:0.8236
et_en Dev loss: 0.4138 r:0.6952
si_en Dev loss: 0.8080 r:0.6006
ne_en Dev loss: 0.4469 r:0.7442
ru_en Dev loss: 0.4803 r:0.7381
Current avg r:0.6190 Best avg r: 0.6383
21:41:08,842 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:42:39,128 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:44:09,456 root INFO Epoch 3 Global steps: 37800 Train loss: 0.3871
en_de Dev loss: 0.8678 r:0.2407
en_zh Dev loss: 0.7917 r:0.4714
ro_en Dev loss: 0.3877 r:0.8261
et_en Dev loss: 0.4266 r:0.7034
si_en Dev loss: 0.7449 r:0.6115
ne_en Dev loss: 0.4802 r:0.7517
ru_en Dev loss: 0.4697 r:0.7453
Current avg r:0.6215 Best avg r: 0.6383
21:48:39,711 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:50:10,41 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:51:40,374 root INFO Epoch 3 Global steps: 38500 Train loss: 0.3676
en_de Dev loss: 0.8519 r:0.2163
en_zh Dev loss: 0.7183 r:0.4838
ro_en Dev loss: 0.3497 r:0.8231
et_en Dev loss: 0.4277 r:0.6939
si_en Dev loss: 0.7494 r:0.6040
ne_en Dev loss: 0.5879 r:0.7507
ru_en Dev loss: 0.4836 r:0.7195
Current avg r:0.6131 Best avg r: 0.6383
21:56:10,954 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
21:57:41,342 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
21:59:11,706 root INFO Epoch 3 Global steps: 39200 Train loss: 0.3675
en_de Dev loss: 0.8486 r:0.2347
en_zh Dev loss: 0.7364 r:0.4809
ro_en Dev loss: 0.3116 r:0.8288
et_en Dev loss: 0.4273 r:0.7042
si_en Dev loss: 0.6232 r:0.6155
ne_en Dev loss: 0.4196 r:0.7556
ru_en Dev loss: 0.4632 r:0.7342
Current avg r:0.6220 Best avg r: 0.6383
22:03:41,927 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:05:12,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:06:42,633 root INFO Epoch 3 Global steps: 39900 Train loss: 0.3611
en_de Dev loss: 0.8845 r:0.2221
en_zh Dev loss: 0.7903 r:0.4649
ro_en Dev loss: 0.3433 r:0.8250
et_en Dev loss: 0.4170 r:0.6982
si_en Dev loss: 0.7452 r:0.6026
ne_en Dev loss: 0.4362 r:0.7600
ru_en Dev loss: 0.4935 r:0.7262
Current avg r:0.6141 Best avg r: 0.6383
22:11:13,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:12:43,635 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:14:14,15 root INFO Epoch 3 Global steps: 40600 Train loss: 0.3612
en_de Dev loss: 0.8555 r:0.2331
en_zh Dev loss: 0.7701 r:0.4769
ro_en Dev loss: 0.3490 r:0.8231
et_en Dev loss: 0.3967 r:0.6959
si_en Dev loss: 0.7006 r:0.6026
ne_en Dev loss: 0.4507 r:0.7590
ru_en Dev loss: 0.5348 r:0.6985
Current avg r:0.6127 Best avg r: 0.6383
22:18:44,544 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:20:14,905 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:21:45,317 root INFO Epoch 3 Global steps: 41300 Train loss: 0.3534
en_de Dev loss: 0.8655 r:0.2294
en_zh Dev loss: 0.7859 r:0.4748
ro_en Dev loss: 0.3823 r:0.8230
et_en Dev loss: 0.4242 r:0.6917
si_en Dev loss: 0.7893 r:0.5992
ne_en Dev loss: 0.5024 r:0.7587
ru_en Dev loss: 0.5296 r:0.7086
Current avg r:0.6122 Best avg r: 0.6383
22:26:16,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:27:46,491 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:29:16,892 root INFO Epoch 3 Global steps: 42000 Train loss: 0.3453
en_de Dev loss: 0.8670 r:0.2443
en_zh Dev loss: 0.8082 r:0.4814
ro_en Dev loss: 0.3871 r:0.8209
et_en Dev loss: 0.4485 r:0.6861
si_en Dev loss: 0.8735 r:0.5919
ne_en Dev loss: 0.5898 r:0.7514
ru_en Dev loss: 0.5460 r:0.7172
Current avg r:0.6133 Best avg r: 0.6383
22:33:49,100 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:35:19,430 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:36:49,809 root INFO Epoch 4 Global steps: 42700 Train loss: 0.3222
en_de Dev loss: 0.8343 r:0.2639
en_zh Dev loss: 0.7028 r:0.4837
ro_en Dev loss: 0.3107 r:0.8297
et_en Dev loss: 0.4084 r:0.6952
si_en Dev loss: 0.6764 r:0.6034
ne_en Dev loss: 0.4236 r:0.7593
ru_en Dev loss: 0.4440 r:0.7303
Current avg r:0.6236 Best avg r: 0.6383
22:41:20,498 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:42:50,894 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:44:21,306 root INFO Epoch 4 Global steps: 43400 Train loss: 0.3073
en_de Dev loss: 0.8392 r:0.2638
en_zh Dev loss: 0.7536 r:0.4818
ro_en Dev loss: 0.3701 r:0.8249
et_en Dev loss: 0.4285 r:0.6937
si_en Dev loss: 0.8195 r:0.5972
ne_en Dev loss: 0.4462 r:0.7536
ru_en Dev loss: 0.5022 r:0.7295
Current avg r:0.6206 Best avg r: 0.6383
22:48:52,91 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:50:22,472 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:51:52,890 root INFO Epoch 4 Global steps: 44100 Train loss: 0.3152
en_de Dev loss: 0.8457 r:0.2505
en_zh Dev loss: 0.7037 r:0.4830
ro_en Dev loss: 0.3311 r:0.8251
et_en Dev loss: 0.4076 r:0.6895
si_en Dev loss: 0.7286 r:0.5956
ne_en Dev loss: 0.4440 r:0.7521
ru_en Dev loss: 0.4803 r:0.7163
Current avg r:0.6160 Best avg r: 0.6383
22:56:23,503 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
22:57:53,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
22:59:24,303 root INFO Epoch 4 Global steps: 44800 Train loss: 0.2976
en_de Dev loss: 0.8770 r:0.2181
en_zh Dev loss: 0.8151 r:0.4669
ro_en Dev loss: 0.3651 r:0.8206
et_en Dev loss: 0.4305 r:0.6826
si_en Dev loss: 0.8245 r:0.5878
ne_en Dev loss: 0.5075 r:0.7580
ru_en Dev loss: 0.5536 r:0.7028
Current avg r:0.6053 Best avg r: 0.6383
23:03:54,974 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:05:25,317 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:06:55,684 root INFO Epoch 4 Global steps: 45500 Train loss: 0.3156
en_de Dev loss: 0.8704 r:0.2084
en_zh Dev loss: 0.7945 r:0.4691
ro_en Dev loss: 0.3753 r:0.8237
et_en Dev loss: 0.4312 r:0.6957
si_en Dev loss: 0.7869 r:0.5852
ne_en Dev loss: 0.4572 r:0.7591
ru_en Dev loss: 0.4688 r:0.7291
Current avg r:0.6101 Best avg r: 0.6383
23:11:26,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:12:56,754 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:14:27,155 root INFO Epoch 4 Global steps: 46200 Train loss: 0.2966
en_de Dev loss: 0.8644 r:0.2119
en_zh Dev loss: 0.7585 r:0.4744
ro_en Dev loss: 0.3331 r:0.8303
et_en Dev loss: 0.4087 r:0.6949
si_en Dev loss: 0.7947 r:0.5883
ne_en Dev loss: 0.5374 r:0.7563
ru_en Dev loss: 0.4797 r:0.7248
Current avg r:0.6115 Best avg r: 0.6383
23:18:57,686 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:20:28,32 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:21:58,389 root INFO Epoch 4 Global steps: 46900 Train loss: 0.3279
en_de Dev loss: 0.8838 r:0.2081
en_zh Dev loss: 0.7931 r:0.4725
ro_en Dev loss: 0.3823 r:0.8230
et_en Dev loss: 0.4446 r:0.6869
si_en Dev loss: 0.9170 r:0.5800
ne_en Dev loss: 0.5323 r:0.7478
ru_en Dev loss: 0.5148 r:0.7234
Current avg r:0.6059 Best avg r: 0.6383
23:26:28,800 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:27:59,116 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:29:29,464 root INFO Epoch 4 Global steps: 47600 Train loss: 0.2941
en_de Dev loss: 0.8658 r:0.2307
en_zh Dev loss: 0.7724 r:0.4823
ro_en Dev loss: 0.3681 r:0.8251
et_en Dev loss: 0.4296 r:0.6949
si_en Dev loss: 0.8456 r:0.5937
ne_en Dev loss: 0.4868 r:0.7528
ru_en Dev loss: 0.5082 r:0.7257
Current avg r:0.6150 Best avg r: 0.6383
23:33:59,689 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:35:29,955 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:37:00,303 root INFO Epoch 4 Global steps: 48300 Train loss: 0.3103
en_de Dev loss: 0.8777 r:0.2156
en_zh Dev loss: 0.8028 r:0.4653
ro_en Dev loss: 0.3689 r:0.8253
et_en Dev loss: 0.4323 r:0.6905
si_en Dev loss: 0.8291 r:0.5948
ne_en Dev loss: 0.5194 r:0.7553
ru_en Dev loss: 0.5108 r:0.7230
Current avg r:0.6100 Best avg r: 0.6383
23:41:30,966 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:43:01,262 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:44:31,608 root INFO Epoch 4 Global steps: 49000 Train loss: 0.3036
en_de Dev loss: 0.8739 r:0.2108
en_zh Dev loss: 0.7900 r:0.4766
ro_en Dev loss: 0.3634 r:0.8269
et_en Dev loss: 0.4331 r:0.6948
si_en Dev loss: 0.7937 r:0.5970
ne_en Dev loss: 0.4740 r:0.7565
ru_en Dev loss: 0.4619 r:0.7435
Current avg r:0.6152 Best avg r: 0.6383
23:49:02,226 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:50:32,547 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:52:02,876 root INFO Epoch 4 Global steps: 49700 Train loss: 0.2960
en_de Dev loss: 0.8660 r:0.2219
en_zh Dev loss: 0.7662 r:0.4737
ro_en Dev loss: 0.3616 r:0.8228
et_en Dev loss: 0.4463 r:0.6944
si_en Dev loss: 0.7655 r:0.5970
ne_en Dev loss: 0.4501 r:0.7580
ru_en Dev loss: 0.4449 r:0.7426
Current avg r:0.6158 Best avg r: 0.6383
23:56:33,408 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
23:56:59,189 root INFO 
id:en_zh cur r: 0.5107 best r: 0.5107
23:58:03,742 root INFO 
id:ru_en cur r: 0.7742 best r: 0.7742
23:58:03,743 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
23:59:34,60 root INFO Epoch 4 Global steps: 50400 Train loss: 0.2947
en_de Dev loss: 0.8615 r:0.2282
en_zh Dev loss: 0.7391 r:0.5097
ro_en Dev loss: 0.3447 r:0.8290
et_en Dev loss: 0.4704 r:0.7038
si_en Dev loss: 0.7058 r:0.6003
ne_en Dev loss: 0.4038 r:0.7562
ru_en Dev loss: 0.3908 r:0.7681
Current avg r:0.6279 Best avg r: 0.6383
00:04:04,658 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:05:34,931 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:07:05,236 root INFO Epoch 4 Global steps: 51100 Train loss: 0.2993
en_de Dev loss: 0.8907 r:0.2243
en_zh Dev loss: 0.7885 r:0.4828
ro_en Dev loss: 0.3958 r:0.8232
et_en Dev loss: 0.4488 r:0.6854
si_en Dev loss: 0.9551 r:0.5824
ne_en Dev loss: 0.5230 r:0.7465
ru_en Dev loss: 0.5629 r:0.7202
Current avg r:0.6093 Best avg r: 0.6383
00:11:35,847 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:13:06,159 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:14:36,523 root INFO Epoch 4 Global steps: 51800 Train loss: 0.3136
en_de Dev loss: 0.8409 r:0.2362
en_zh Dev loss: 0.6921 r:0.4875
ro_en Dev loss: 0.3029 r:0.8290
et_en Dev loss: 0.4101 r:0.6942
si_en Dev loss: 0.7158 r:0.5951
ne_en Dev loss: 0.3945 r:0.7624
ru_en Dev loss: 0.4021 r:0.7458
Current avg r:0.6215 Best avg r: 0.6383
00:19:06,986 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:20:37,303 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:22:07,674 root INFO Epoch 4 Global steps: 52500 Train loss: 0.2937
en_de Dev loss: 0.8513 r:0.2343
en_zh Dev loss: 0.7691 r:0.4727
ro_en Dev loss: 0.3479 r:0.8285
et_en Dev loss: 0.4425 r:0.6910
si_en Dev loss: 0.8126 r:0.5807
ne_en Dev loss: 0.4356 r:0.7499
ru_en Dev loss: 0.5109 r:0.7166
Current avg r:0.6105 Best avg r: 0.6383
00:26:39,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:28:10,322 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:29:40,715 root INFO Epoch 5 Global steps: 53200 Train loss: 0.2709
en_de Dev loss: 0.8639 r:0.2184
en_zh Dev loss: 0.7455 r:0.4900
ro_en Dev loss: 0.3323 r:0.8302
et_en Dev loss: 0.4529 r:0.6948
si_en Dev loss: 0.7279 r:0.5920
ne_en Dev loss: 0.4143 r:0.7533
ru_en Dev loss: 0.4363 r:0.7432
Current avg r:0.6174 Best avg r: 0.6383
00:34:11,323 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:35:41,639 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:37:11,960 root INFO Epoch 5 Global steps: 53900 Train loss: 0.2613
en_de Dev loss: 0.8595 r:0.2236
en_zh Dev loss: 0.7979 r:0.4716
ro_en Dev loss: 0.3319 r:0.8324
et_en Dev loss: 0.4403 r:0.6971
si_en Dev loss: 0.7333 r:0.5931
ne_en Dev loss: 0.4360 r:0.7501
ru_en Dev loss: 0.4577 r:0.7364
Current avg r:0.6149 Best avg r: 0.6383
00:41:42,512 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:43:12,809 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:44:43,143 root INFO Epoch 5 Global steps: 54600 Train loss: 0.2604
en_de Dev loss: 0.8488 r:0.2335
en_zh Dev loss: 0.7773 r:0.4763
ro_en Dev loss: 0.3160 r:0.8309
et_en Dev loss: 0.4256 r:0.6881
si_en Dev loss: 0.8694 r:0.5827
ne_en Dev loss: 0.5166 r:0.7482
ru_en Dev loss: 0.4719 r:0.7253
Current avg r:0.6121 Best avg r: 0.6383
00:49:13,724 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:50:44,21 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:52:14,400 root INFO Epoch 5 Global steps: 55300 Train loss: 0.2593
en_de Dev loss: 0.8594 r:0.2278
en_zh Dev loss: 0.8056 r:0.4752
ro_en Dev loss: 0.3628 r:0.8270
et_en Dev loss: 0.4633 r:0.6856
si_en Dev loss: 0.8281 r:0.5851
ne_en Dev loss: 0.4347 r:0.7504
ru_en Dev loss: 0.5195 r:0.7235
Current avg r:0.6107 Best avg r: 0.6383
00:56:45,30 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
00:58:15,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
00:59:45,742 root INFO Epoch 5 Global steps: 56000 Train loss: 0.2638
en_de Dev loss: 0.8430 r:0.2371
en_zh Dev loss: 0.7930 r:0.4534
ro_en Dev loss: 0.3428 r:0.8254
et_en Dev loss: 0.4528 r:0.6840
si_en Dev loss: 0.8489 r:0.5807
ne_en Dev loss: 0.4090 r:0.7412
ru_en Dev loss: 0.4983 r:0.7139
Current avg r:0.6051 Best avg r: 0.6383
01:04:16,443 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:05:46,722 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:07:17,8 root INFO Epoch 5 Global steps: 56700 Train loss: 0.2654
en_de Dev loss: 0.8507 r:0.2412
en_zh Dev loss: 0.7757 r:0.4725
ro_en Dev loss: 0.3489 r:0.8265
et_en Dev loss: 0.4473 r:0.6788
si_en Dev loss: 0.8324 r:0.5847
ne_en Dev loss: 0.4647 r:0.7514
ru_en Dev loss: 0.4869 r:0.7257
Current avg r:0.6116 Best avg r: 0.6383
01:11:47,583 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:13:17,852 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:14:48,215 root INFO Epoch 5 Global steps: 57400 Train loss: 0.2550
en_de Dev loss: 0.8678 r:0.2371
en_zh Dev loss: 0.7912 r:0.4689
ro_en Dev loss: 0.3379 r:0.8271
et_en Dev loss: 0.4512 r:0.6734
si_en Dev loss: 0.8742 r:0.5756
ne_en Dev loss: 0.5480 r:0.7472
ru_en Dev loss: 0.5223 r:0.7157
Current avg r:0.6064 Best avg r: 0.6383
01:19:18,808 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:20:49,57 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:22:19,363 root INFO Epoch 5 Global steps: 58100 Train loss: 0.2500
en_de Dev loss: 0.8784 r:0.2306
en_zh Dev loss: 0.7977 r:0.4739
ro_en Dev loss: 0.3442 r:0.8274
et_en Dev loss: 0.4667 r:0.6743
si_en Dev loss: 0.8267 r:0.5760
ne_en Dev loss: 0.5171 r:0.7439
ru_en Dev loss: 0.5092 r:0.7213
Current avg r:0.6068 Best avg r: 0.6383
01:26:49,448 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:28:19,746 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:29:50,44 root INFO Epoch 5 Global steps: 58800 Train loss: 0.2556
en_de Dev loss: 0.8480 r:0.2488
en_zh Dev loss: 0.7646 r:0.4678
ro_en Dev loss: 0.3160 r:0.8291
et_en Dev loss: 0.4453 r:0.6811
si_en Dev loss: 0.7551 r:0.5837
ne_en Dev loss: 0.4460 r:0.7431
ru_en Dev loss: 0.4450 r:0.7330
Current avg r:0.6124 Best avg r: 0.6383
01:34:20,89 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:35:50,354 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:37:20,634 root INFO Epoch 5 Global steps: 59500 Train loss: 0.2567
en_de Dev loss: 0.8834 r:0.2315
en_zh Dev loss: 0.7864 r:0.4850
ro_en Dev loss: 0.3295 r:0.8301
et_en Dev loss: 0.4949 r:0.6916
si_en Dev loss: 0.7158 r:0.5905
ne_en Dev loss: 0.4380 r:0.7359
ru_en Dev loss: 0.4476 r:0.7383
Current avg r:0.6147 Best avg r: 0.6383
01:41:51,178 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:43:21,446 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:44:51,773 root INFO Epoch 5 Global steps: 60200 Train loss: 0.2497
en_de Dev loss: 0.8759 r:0.2145
en_zh Dev loss: 0.7901 r:0.4614
ro_en Dev loss: 0.3281 r:0.8299
et_en Dev loss: 0.4474 r:0.6801
si_en Dev loss: 0.7495 r:0.5823
ne_en Dev loss: 0.5352 r:0.7370
ru_en Dev loss: 0.4993 r:0.7110
Current avg r:0.6023 Best avg r: 0.6383
01:49:22,464 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:50:52,803 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:52:23,161 root INFO Epoch 5 Global steps: 60900 Train loss: 0.2590
en_de Dev loss: 0.9144 r:0.2242
en_zh Dev loss: 0.8742 r:0.4682
ro_en Dev loss: 0.4156 r:0.8278
et_en Dev loss: 0.4883 r:0.6829
si_en Dev loss: 0.8879 r:0.5804
ne_en Dev loss: 0.5770 r:0.7306
ru_en Dev loss: 0.6157 r:0.7067
Current avg r:0.6030 Best avg r: 0.6383
01:56:53,590 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
01:57:32,316 root INFO 
id:ro_en cur r: 0.8356 best r: 0.8356
01:58:23,977 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
01:59:54,325 root INFO Epoch 5 Global steps: 61600 Train loss: 0.2642
en_de Dev loss: 0.8610 r:0.2208
en_zh Dev loss: 0.7421 r:0.4687
ro_en Dev loss: 0.3133 r:0.8322
et_en Dev loss: 0.4224 r:0.6888
si_en Dev loss: 0.7949 r:0.5833
ne_en Dev loss: 0.4807 r:0.7324
ru_en Dev loss: 0.4346 r:0.7384
Current avg r:0.6092 Best avg r: 0.6383
02:04:24,703 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:05:54,951 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:07:25,181 root INFO Epoch 5 Global steps: 62300 Train loss: 0.2434
en_de Dev loss: 0.8765 r:0.2095
en_zh Dev loss: 0.7529 r:0.4727
ro_en Dev loss: 0.3389 r:0.8308
et_en Dev loss: 0.4662 r:0.6782
si_en Dev loss: 0.7701 r:0.5792
ne_en Dev loss: 0.4945 r:0.7314
ru_en Dev loss: 0.4811 r:0.7219
Current avg r:0.6034 Best avg r: 0.6383
02:11:55,217 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:13:25,436 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:14:55,679 root INFO Epoch 5 Global steps: 63000 Train loss: 0.2475
en_de Dev loss: 0.8948 r:0.2047
en_zh Dev loss: 0.7535 r:0.4705
ro_en Dev loss: 0.3263 r:0.8284
et_en Dev loss: 0.4442 r:0.6805
si_en Dev loss: 0.8131 r:0.5727
ne_en Dev loss: 0.4503 r:0.7336
ru_en Dev loss: 0.4616 r:0.7293
Current avg r:0.6028 Best avg r: 0.6383
02:19:27,278 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:20:57,480 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:22:27,739 root INFO Epoch 6 Global steps: 63700 Train loss: 0.2242
en_de Dev loss: 0.9016 r:0.2088
en_zh Dev loss: 0.7829 r:0.4719
ro_en Dev loss: 0.3770 r:0.8244
et_en Dev loss: 0.4737 r:0.6746
si_en Dev loss: 0.8911 r:0.5773
ne_en Dev loss: 0.4972 r:0.7321
ru_en Dev loss: 0.5427 r:0.7120
Current avg r:0.6002 Best avg r: 0.6383
02:26:57,735 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:28:28,1 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:29:58,175 root INFO Epoch 6 Global steps: 64400 Train loss: 0.2193
en_de Dev loss: 0.8947 r:0.2024
en_zh Dev loss: 0.7987 r:0.4534
ro_en Dev loss: 0.3275 r:0.8278
et_en Dev loss: 0.4626 r:0.6711
si_en Dev loss: 0.8629 r:0.5680
ne_en Dev loss: 0.4560 r:0.7223
ru_en Dev loss: 0.5134 r:0.7091
Current avg r:0.5934 Best avg r: 0.6383
02:34:28,134 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:35:58,309 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:37:28,489 root INFO Epoch 6 Global steps: 65100 Train loss: 0.2362
en_de Dev loss: 0.8721 r:0.1937
en_zh Dev loss: 0.7439 r:0.4591
ro_en Dev loss: 0.3193 r:0.8282
et_en Dev loss: 0.4375 r:0.6737
si_en Dev loss: 0.8093 r:0.5674
ne_en Dev loss: 0.4849 r:0.7199
ru_en Dev loss: 0.4771 r:0.7173
Current avg r:0.5942 Best avg r: 0.6383
02:41:58,561 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:43:28,757 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:44:59,0 root INFO Epoch 6 Global steps: 65800 Train loss: 0.2174
en_de Dev loss: 0.8820 r:0.2115
en_zh Dev loss: 0.7800 r:0.4531
ro_en Dev loss: 0.3074 r:0.8311
et_en Dev loss: 0.4578 r:0.6782
si_en Dev loss: 0.7713 r:0.5682
ne_en Dev loss: 0.4754 r:0.7293
ru_en Dev loss: 0.4242 r:0.7415
Current avg r:0.6018 Best avg r: 0.6383
02:49:29,64 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:50:59,285 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
02:52:29,570 root INFO Epoch 6 Global steps: 66500 Train loss: 0.2149
en_de Dev loss: 0.8966 r:0.2158
en_zh Dev loss: 0.8566 r:0.4659
ro_en Dev loss: 0.3821 r:0.8281
et_en Dev loss: 0.4737 r:0.6756
si_en Dev loss: 0.9024 r:0.5653
ne_en Dev loss: 0.5844 r:0.7291
ru_en Dev loss: 0.5170 r:0.7290
Current avg r:0.6013 Best avg r: 0.6383
02:56:59,606 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
02:58:29,896 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:00:00,165 root INFO Epoch 6 Global steps: 67200 Train loss: 0.2137
en_de Dev loss: 0.8965 r:0.2090
en_zh Dev loss: 0.8151 r:0.4553
ro_en Dev loss: 0.3644 r:0.8268
et_en Dev loss: 0.5312 r:0.6699
si_en Dev loss: 0.8239 r:0.5663
ne_en Dev loss: 0.4743 r:0.7356
ru_en Dev loss: 0.4706 r:0.7243
Current avg r:0.5982 Best avg r: 0.6383
03:04:30,314 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:06:00,540 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:07:30,812 root INFO Epoch 6 Global steps: 67900 Train loss: 0.2156
en_de Dev loss: 0.9170 r:0.2072
en_zh Dev loss: 0.8488 r:0.4686
ro_en Dev loss: 0.3902 r:0.8262
et_en Dev loss: 0.4779 r:0.6689
si_en Dev loss: 1.0176 r:0.5584
ne_en Dev loss: 0.6111 r:0.7318
ru_en Dev loss: 0.5350 r:0.7238
Current avg r:0.5979 Best avg r: 0.6383
03:12:00,919 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:13:31,132 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:15:01,380 root INFO Epoch 6 Global steps: 68600 Train loss: 0.2096
en_de Dev loss: 0.8927 r:0.1929
en_zh Dev loss: 0.7486 r:0.4786
ro_en Dev loss: 0.3212 r:0.8324
et_en Dev loss: 0.4670 r:0.6847
si_en Dev loss: 0.7220 r:0.5809
ne_en Dev loss: 0.4372 r:0.7408
ru_en Dev loss: 0.4090 r:0.7469
Current avg r:0.6082 Best avg r: 0.6383
03:19:31,402 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:21:01,641 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:22:31,940 root INFO Epoch 6 Global steps: 69300 Train loss: 0.2171
en_de Dev loss: 0.8818 r:0.1957
en_zh Dev loss: 0.7790 r:0.4571
ro_en Dev loss: 0.3258 r:0.8274
et_en Dev loss: 0.4801 r:0.6861
si_en Dev loss: 0.7636 r:0.5736
ne_en Dev loss: 0.4570 r:0.7305
ru_en Dev loss: 0.4383 r:0.7333
Current avg r:0.6005 Best avg r: 0.6383
03:27:01,937 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:28:32,224 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:30:02,521 root INFO Epoch 6 Global steps: 70000 Train loss: 0.2117
en_de Dev loss: 0.8764 r:0.1801
en_zh Dev loss: 0.7362 r:0.4640
ro_en Dev loss: 0.3087 r:0.8292
et_en Dev loss: 0.4564 r:0.6806
si_en Dev loss: 0.7976 r:0.5652
ne_en Dev loss: 0.4552 r:0.7384
ru_en Dev loss: 0.4251 r:0.7319
Current avg r:0.5985 Best avg r: 0.6383
03:34:32,677 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:36:02,950 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:37:33,236 root INFO Epoch 6 Global steps: 70700 Train loss: 0.2168
en_de Dev loss: 0.8869 r:0.1962
en_zh Dev loss: 0.7524 r:0.4834
ro_en Dev loss: 0.3302 r:0.8306
et_en Dev loss: 0.4901 r:0.6780
si_en Dev loss: 0.7987 r:0.5659
ne_en Dev loss: 0.4388 r:0.7345
ru_en Dev loss: 0.4374 r:0.7368
Current avg r:0.6036 Best avg r: 0.6383
03:42:03,440 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:43:33,705 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:45:04,1 root INFO Epoch 6 Global steps: 71400 Train loss: 0.2090
en_de Dev loss: 0.8858 r:0.2088
en_zh Dev loss: 0.7664 r:0.4792
ro_en Dev loss: 0.3566 r:0.8247
et_en Dev loss: 0.4947 r:0.6710
si_en Dev loss: 0.8070 r:0.5672
ne_en Dev loss: 0.5284 r:0.7334
ru_en Dev loss: 0.4648 r:0.7273
Current avg r:0.6017 Best avg r: 0.6383
03:49:34,172 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:51:04,448 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
03:52:34,779 root INFO Epoch 6 Global steps: 72100 Train loss: 0.2120
en_de Dev loss: 0.8787 r:0.1824
en_zh Dev loss: 0.7548 r:0.4516
ro_en Dev loss: 0.3273 r:0.8269
et_en Dev loss: 0.4573 r:0.6688
si_en Dev loss: 0.7863 r:0.5690
ne_en Dev loss: 0.5318 r:0.7329
ru_en Dev loss: 0.4369 r:0.7251
Current avg r:0.5938 Best avg r: 0.6383
03:57:04,925 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
03:58:35,243 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:00:05,563 root INFO Epoch 6 Global steps: 72800 Train loss: 0.2248
en_de Dev loss: 0.9203 r:0.1955
en_zh Dev loss: 0.8485 r:0.4706
ro_en Dev loss: 0.3774 r:0.8225
et_en Dev loss: 0.4696 r:0.6721
si_en Dev loss: 0.8836 r:0.5629
ne_en Dev loss: 0.5454 r:0.7352
ru_en Dev loss: 0.5175 r:0.7230
Current avg r:0.5974 Best avg r: 0.6383
04:04:35,697 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:06:05,956 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:07:36,241 root INFO Epoch 6 Global steps: 73500 Train loss: 0.2131
en_de Dev loss: 0.8970 r:0.2103
en_zh Dev loss: 0.8157 r:0.4587
ro_en Dev loss: 0.3784 r:0.8211
et_en Dev loss: 0.4879 r:0.6706
si_en Dev loss: 0.8690 r:0.5621
ne_en Dev loss: 0.5295 r:0.7290
ru_en Dev loss: 0.4741 r:0.7333
Current avg r:0.5979 Best avg r: 0.6383
04:12:07,935 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:13:38,179 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:15:08,472 root INFO Epoch 7 Global steps: 74200 Train loss: 0.1844
en_de Dev loss: 0.9077 r:0.2105
en_zh Dev loss: 0.8266 r:0.4609
ro_en Dev loss: 0.3675 r:0.8209
et_en Dev loss: 0.4932 r:0.6703
si_en Dev loss: 0.8907 r:0.5554
ne_en Dev loss: 0.5390 r:0.7286
ru_en Dev loss: 0.4966 r:0.7208
Current avg r:0.5954 Best avg r: 0.6383
04:19:38,880 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:21:09,147 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:22:39,465 root INFO Epoch 7 Global steps: 74900 Train loss: 0.1857
en_de Dev loss: 0.8999 r:0.1945
en_zh Dev loss: 0.8379 r:0.4485
ro_en Dev loss: 0.3773 r:0.8206
et_en Dev loss: 0.4699 r:0.6648
si_en Dev loss: 0.8747 r:0.5524
ne_en Dev loss: 0.5891 r:0.7298
ru_en Dev loss: 0.5033 r:0.7165
Current avg r:0.5896 Best avg r: 0.6383
04:27:09,723 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:28:40,37 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:30:10,311 root INFO Epoch 7 Global steps: 75600 Train loss: 0.1926
en_de Dev loss: 0.8994 r:0.2096
en_zh Dev loss: 0.7515 r:0.4833
ro_en Dev loss: 0.3312 r:0.8262
et_en Dev loss: 0.4773 r:0.6749
si_en Dev loss: 0.8166 r:0.5594
ne_en Dev loss: 0.4823 r:0.7359
ru_en Dev loss: 0.4375 r:0.7344
Current avg r:0.6034 Best avg r: 0.6383
04:34:40,741 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:36:11,59 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:37:41,393 root INFO Epoch 7 Global steps: 76300 Train loss: 0.1866
en_de Dev loss: 0.9036 r:0.2136
en_zh Dev loss: 0.8213 r:0.4675
ro_en Dev loss: 0.3703 r:0.8269
et_en Dev loss: 0.4902 r:0.6778
si_en Dev loss: 0.8165 r:0.5634
ne_en Dev loss: 0.4930 r:0.7359
ru_en Dev loss: 0.4818 r:0.7239
Current avg r:0.6013 Best avg r: 0.6383
04:42:12,167 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:43:42,455 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:45:12,735 root INFO Epoch 7 Global steps: 77000 Train loss: 0.1868
en_de Dev loss: 0.8966 r:0.2028
en_zh Dev loss: 0.8043 r:0.4627
ro_en Dev loss: 0.3521 r:0.8233
et_en Dev loss: 0.4749 r:0.6658
si_en Dev loss: 0.8530 r:0.5625
ne_en Dev loss: 0.5780 r:0.7326
ru_en Dev loss: 0.4693 r:0.7245
Current avg r:0.5963 Best avg r: 0.6383
04:49:43,356 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:51:13,638 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
04:52:43,960 root INFO Epoch 7 Global steps: 77700 Train loss: 0.1851
en_de Dev loss: 0.8952 r:0.2130
en_zh Dev loss: 0.8275 r:0.4562
ro_en Dev loss: 0.3596 r:0.8216
et_en Dev loss: 0.4926 r:0.6589
si_en Dev loss: 0.9637 r:0.5542
ne_en Dev loss: 0.6246 r:0.7323
ru_en Dev loss: 0.5148 r:0.7158
Current avg r:0.5932 Best avg r: 0.6383
04:57:14,54 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
04:58:44,318 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:00:14,603 root INFO Epoch 7 Global steps: 78400 Train loss: 0.1861
en_de Dev loss: 0.8951 r:0.2124
en_zh Dev loss: 0.7560 r:0.4750
ro_en Dev loss: 0.3364 r:0.8208
et_en Dev loss: 0.4702 r:0.6687
si_en Dev loss: 0.8497 r:0.5584
ne_en Dev loss: 0.5000 r:0.7235
ru_en Dev loss: 0.4645 r:0.7279
Current avg r:0.5981 Best avg r: 0.6383
05:04:44,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:06:15,24 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:07:45,318 root INFO Epoch 7 Global steps: 79100 Train loss: 0.1822
en_de Dev loss: 0.8976 r:0.2020
en_zh Dev loss: 0.8139 r:0.4668
ro_en Dev loss: 0.3885 r:0.8225
et_en Dev loss: 0.5101 r:0.6615
si_en Dev loss: 1.0182 r:0.5470
ne_en Dev loss: 0.6543 r:0.7278
ru_en Dev loss: 0.5170 r:0.7269
Current avg r:0.5935 Best avg r: 0.6383
05:12:15,449 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:13:45,735 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:15:16,17 root INFO Epoch 7 Global steps: 79800 Train loss: 0.1827
en_de Dev loss: 0.8849 r:0.2074
en_zh Dev loss: 0.7447 r:0.4709
ro_en Dev loss: 0.3247 r:0.8276
et_en Dev loss: 0.4630 r:0.6670
si_en Dev loss: 0.7927 r:0.5590
ne_en Dev loss: 0.5042 r:0.7205
ru_en Dev loss: 0.4595 r:0.7228
Current avg r:0.5965 Best avg r: 0.6383
05:19:46,158 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:21:16,417 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:22:46,740 root INFO Epoch 7 Global steps: 80500 Train loss: 0.1938
en_de Dev loss: 0.9035 r:0.2047
en_zh Dev loss: 0.8195 r:0.4730
ro_en Dev loss: 0.3652 r:0.8271
et_en Dev loss: 0.5172 r:0.6624
si_en Dev loss: 0.9161 r:0.5608
ne_en Dev loss: 0.5386 r:0.7268
ru_en Dev loss: 0.4787 r:0.7365
Current avg r:0.5987 Best avg r: 0.6383
05:27:17,115 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:28:47,439 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:30:17,780 root INFO Epoch 7 Global steps: 81200 Train loss: 0.1859
en_de Dev loss: 0.8947 r:0.2021
en_zh Dev loss: 0.7922 r:0.4539
ro_en Dev loss: 0.3474 r:0.8281
et_en Dev loss: 0.5296 r:0.6670
si_en Dev loss: 0.8248 r:0.5598
ne_en Dev loss: 0.5171 r:0.7258
ru_en Dev loss: 0.4601 r:0.7244
Current avg r:0.5944 Best avg r: 0.6383
05:34:48,117 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:36:18,381 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:37:48,645 root INFO Epoch 7 Global steps: 81900 Train loss: 0.1902
en_de Dev loss: 0.9129 r:0.2028
en_zh Dev loss: 0.7617 r:0.4841
ro_en Dev loss: 0.3530 r:0.8288
et_en Dev loss: 0.5279 r:0.6745
si_en Dev loss: 0.8399 r:0.5639
ne_en Dev loss: 0.5503 r:0.7208
ru_en Dev loss: 0.4777 r:0.7244
Current avg r:0.5999 Best avg r: 0.6383
05:42:18,752 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:43:48,970 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:45:19,250 root INFO Epoch 7 Global steps: 82600 Train loss: 0.1788
en_de Dev loss: 0.9214 r:0.1895
en_zh Dev loss: 0.7759 r:0.4853
ro_en Dev loss: 0.3525 r:0.8256
et_en Dev loss: 0.4786 r:0.6669
si_en Dev loss: 0.8656 r:0.5617
ne_en Dev loss: 0.5527 r:0.7232
ru_en Dev loss: 0.4912 r:0.7259
Current avg r:0.5969 Best avg r: 0.6383
05:49:49,585 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:51:19,817 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
05:52:50,121 root INFO Epoch 7 Global steps: 83300 Train loss: 0.1810
en_de Dev loss: 0.9171 r:0.1802
en_zh Dev loss: 0.7936 r:0.4736
ro_en Dev loss: 0.3715 r:0.8227
et_en Dev loss: 0.4966 r:0.6560
si_en Dev loss: 0.9665 r:0.5507
ne_en Dev loss: 0.6071 r:0.7219
ru_en Dev loss: 0.4621 r:0.7374
Current avg r:0.5918 Best avg r: 0.6383
05:57:20,293 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
05:58:50,592 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:00:20,877 root INFO Epoch 7 Global steps: 84000 Train loss: 0.1829
en_de Dev loss: 0.8938 r:0.1947
en_zh Dev loss: 0.8100 r:0.4618
ro_en Dev loss: 0.3452 r:0.8275
et_en Dev loss: 0.4940 r:0.6625
si_en Dev loss: 0.8980 r:0.5519
ne_en Dev loss: 0.5715 r:0.7195
ru_en Dev loss: 0.4764 r:0.7239
Current avg r:0.5917 Best avg r: 0.6383
06:04:52,982 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:06:23,263 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:07:53,572 root INFO Epoch 8 Global steps: 84700 Train loss: 0.1670
en_de Dev loss: 0.9244 r:0.2113
en_zh Dev loss: 0.8234 r:0.4795
ro_en Dev loss: 0.3713 r:0.8260
et_en Dev loss: 0.5356 r:0.6654
si_en Dev loss: 0.8853 r:0.5592
ne_en Dev loss: 0.5453 r:0.7235
ru_en Dev loss: 0.4768 r:0.7265
Current avg r:0.5988 Best avg r: 0.6383
06:12:24,161 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:13:54,395 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:15:24,672 root INFO Epoch 8 Global steps: 85400 Train loss: 0.1615
en_de Dev loss: 0.9273 r:0.1962
en_zh Dev loss: 0.7881 r:0.4776
ro_en Dev loss: 0.3464 r:0.8273
et_en Dev loss: 0.4908 r:0.6787
si_en Dev loss: 0.8625 r:0.5639
ne_en Dev loss: 0.4916 r:0.7279
ru_en Dev loss: 0.4575 r:0.7336
Current avg r:0.6007 Best avg r: 0.6383
06:19:53,633 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:21:23,415 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:22:53,267 root INFO Epoch 8 Global steps: 86100 Train loss: 0.1681
en_de Dev loss: 0.9266 r:0.1874
en_zh Dev loss: 0.8105 r:0.4645
ro_en Dev loss: 0.3575 r:0.8247
et_en Dev loss: 0.5130 r:0.6627
si_en Dev loss: 0.9044 r:0.5566
ne_en Dev loss: 0.5786 r:0.7180
ru_en Dev loss: 0.4773 r:0.7278
Current avg r:0.5917 Best avg r: 0.6383
06:27:21,736 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:28:51,471 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:30:21,135 root INFO Epoch 8 Global steps: 86800 Train loss: 0.1623
en_de Dev loss: 0.8935 r:0.1925
en_zh Dev loss: 0.7816 r:0.4577
ro_en Dev loss: 0.3364 r:0.8220
et_en Dev loss: 0.4964 r:0.6675
si_en Dev loss: 0.8332 r:0.5605
ne_en Dev loss: 0.5478 r:0.7093
ru_en Dev loss: 0.4449 r:0.7300
Current avg r:0.5914 Best avg r: 0.6383
06:34:49,666 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:36:19,596 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:37:49,455 root INFO Epoch 8 Global steps: 87500 Train loss: 0.1609
en_de Dev loss: 0.9216 r:0.1978
en_zh Dev loss: 0.7831 r:0.4778
ro_en Dev loss: 0.3560 r:0.8234
et_en Dev loss: 0.5180 r:0.6672
si_en Dev loss: 0.8491 r:0.5641
ne_en Dev loss: 0.5315 r:0.7208
ru_en Dev loss: 0.4723 r:0.7289
Current avg r:0.5972 Best avg r: 0.6383
06:42:17,923 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:43:47,726 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:45:17,580 root INFO Epoch 8 Global steps: 88200 Train loss: 0.1563
en_de Dev loss: 0.9098 r:0.1921
en_zh Dev loss: 0.7873 r:0.4572
ro_en Dev loss: 0.3295 r:0.8227
et_en Dev loss: 0.4840 r:0.6604
si_en Dev loss: 0.8606 r:0.5559
ne_en Dev loss: 0.5440 r:0.7195
ru_en Dev loss: 0.5030 r:0.7066
Current avg r:0.5878 Best avg r: 0.6383
06:49:46,59 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:51:15,834 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
06:52:45,690 root INFO Epoch 8 Global steps: 88900 Train loss: 0.1641
en_de Dev loss: 0.9379 r:0.1771
en_zh Dev loss: 0.7828 r:0.4884
ro_en Dev loss: 0.3470 r:0.8260
et_en Dev loss: 0.5199 r:0.6714
si_en Dev loss: 0.8251 r:0.5630
ne_en Dev loss: 0.4617 r:0.7226
ru_en Dev loss: 0.4671 r:0.7326
Current avg r:0.5973 Best avg r: 0.6383
06:57:14,150 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
06:58:44,72 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:00:13,925 root INFO Epoch 8 Global steps: 89600 Train loss: 0.1584
en_de Dev loss: 0.9024 r:0.1932
en_zh Dev loss: 0.7776 r:0.4704
ro_en Dev loss: 0.3380 r:0.8248
et_en Dev loss: 0.4999 r:0.6692
si_en Dev loss: 0.8244 r:0.5625
ne_en Dev loss: 0.5026 r:0.7220
ru_en Dev loss: 0.5012 r:0.7073
Current avg r:0.5928 Best avg r: 0.6383
07:04:42,427 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:06:12,332 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:07:42,174 root INFO Epoch 8 Global steps: 90300 Train loss: 0.1590
en_de Dev loss: 0.8986 r:0.1886
en_zh Dev loss: 0.7695 r:0.4716
ro_en Dev loss: 0.3374 r:0.8265
et_en Dev loss: 0.4925 r:0.6608
si_en Dev loss: 0.9501 r:0.5494
ne_en Dev loss: 0.6277 r:0.7271
ru_en Dev loss: 0.4655 r:0.7307
Current avg r:0.5935 Best avg r: 0.6383
07:12:10,662 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:13:40,580 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:15:10,415 root INFO Epoch 8 Global steps: 91000 Train loss: 0.1595
en_de Dev loss: 0.8908 r:0.1733
en_zh Dev loss: 0.7446 r:0.4677
ro_en Dev loss: 0.3242 r:0.8253
et_en Dev loss: 0.4760 r:0.6592
si_en Dev loss: 0.8462 r:0.5551
ne_en Dev loss: 0.5282 r:0.7220
ru_en Dev loss: 0.4550 r:0.7192
Current avg r:0.5889 Best avg r: 0.6383
07:19:38,821 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:21:08,721 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:22:38,564 root INFO Epoch 8 Global steps: 91700 Train loss: 0.1599
en_de Dev loss: 0.9115 r:0.1820
en_zh Dev loss: 0.7906 r:0.4809
ro_en Dev loss: 0.3539 r:0.8268
et_en Dev loss: 0.4812 r:0.6578
si_en Dev loss: 0.9320 r:0.5525
ne_en Dev loss: 0.6215 r:0.7175
ru_en Dev loss: 0.4994 r:0.7258
Current avg r:0.5919 Best avg r: 0.6383
07:27:06,952 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:28:36,856 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:30:06,706 root INFO Epoch 8 Global steps: 92400 Train loss: 0.1649
en_de Dev loss: 0.9156 r:0.1780
en_zh Dev loss: 0.7995 r:0.4608
ro_en Dev loss: 0.3329 r:0.8252
et_en Dev loss: 0.4823 r:0.6634
si_en Dev loss: 0.8323 r:0.5585
ne_en Dev loss: 0.5806 r:0.7207
ru_en Dev loss: 0.4466 r:0.7393
Current avg r:0.5923 Best avg r: 0.6383
07:34:35,192 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:36:05,97 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:37:34,921 root INFO Epoch 8 Global steps: 93100 Train loss: 0.1656
en_de Dev loss: 0.9156 r:0.1778
en_zh Dev loss: 0.7809 r:0.4687
ro_en Dev loss: 0.3515 r:0.8231
et_en Dev loss: 0.5060 r:0.6508
si_en Dev loss: 1.0006 r:0.5430
ne_en Dev loss: 0.6222 r:0.7122
ru_en Dev loss: 0.4706 r:0.7249
Current avg r:0.5858 Best avg r: 0.6383
07:42:03,364 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:43:33,68 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:45:02,764 root INFO Epoch 8 Global steps: 93800 Train loss: 0.1622
en_de Dev loss: 0.9085 r:0.1766
en_zh Dev loss: 0.8212 r:0.4644
ro_en Dev loss: 0.3492 r:0.8256
et_en Dev loss: 0.4870 r:0.6637
si_en Dev loss: 0.9072 r:0.5563
ne_en Dev loss: 0.6020 r:0.7216
ru_en Dev loss: 0.4725 r:0.7282
Current avg r:0.5909 Best avg r: 0.6383
07:49:31,268 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:51:01,168 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
07:52:31,11 root INFO Epoch 8 Global steps: 94500 Train loss: 0.1515
en_de Dev loss: 0.9096 r:0.1771
en_zh Dev loss: 0.7932 r:0.4673
ro_en Dev loss: 0.3371 r:0.8269
et_en Dev loss: 0.4866 r:0.6596
si_en Dev loss: 0.8987 r:0.5525
ne_en Dev loss: 0.5926 r:0.7246
ru_en Dev loss: 0.4804 r:0.7246
Current avg r:0.5904 Best avg r: 0.6383
07:57:01,99 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
07:58:31,27 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:00:00,839 root INFO Epoch 9 Global steps: 95200 Train loss: 0.1495
en_de Dev loss: 0.9060 r:0.1843
en_zh Dev loss: 0.7434 r:0.4894
ro_en Dev loss: 0.3299 r:0.8276
et_en Dev loss: 0.4742 r:0.6643
si_en Dev loss: 0.8875 r:0.5544
ne_en Dev loss: 0.6349 r:0.7259
ru_en Dev loss: 0.4220 r:0.7486
Current avg r:0.5992 Best avg r: 0.6383
08:04:29,333 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:05:59,264 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:07:29,98 root INFO Epoch 9 Global steps: 95900 Train loss: 0.1448
en_de Dev loss: 0.9409 r:0.1877
en_zh Dev loss: 0.8174 r:0.4769
ro_en Dev loss: 0.3712 r:0.8254
et_en Dev loss: 0.5144 r:0.6566
si_en Dev loss: 0.9551 r:0.5466
ne_en Dev loss: 0.6130 r:0.7184
ru_en Dev loss: 0.4898 r:0.7318
Current avg r:0.5919 Best avg r: 0.6383
08:11:57,629 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:13:27,517 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:14:57,359 root INFO Epoch 9 Global steps: 96600 Train loss: 0.1402
en_de Dev loss: 0.9095 r:0.1947
en_zh Dev loss: 0.7604 r:0.4850
ro_en Dev loss: 0.3401 r:0.8245
et_en Dev loss: 0.4912 r:0.6626
si_en Dev loss: 0.8734 r:0.5561
ne_en Dev loss: 0.5531 r:0.7231
ru_en Dev loss: 0.4555 r:0.7333
Current avg r:0.5970 Best avg r: 0.6383
08:19:25,793 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:20:55,685 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:22:25,455 root INFO Epoch 9 Global steps: 97300 Train loss: 0.1417
en_de Dev loss: 0.8946 r:0.1950
en_zh Dev loss: 0.8147 r:0.4768
ro_en Dev loss: 0.3499 r:0.8207
et_en Dev loss: 0.4781 r:0.6580
si_en Dev loss: 0.9239 r:0.5489
ne_en Dev loss: 0.6153 r:0.7193
ru_en Dev loss: 0.4808 r:0.7238
Current avg r:0.5918 Best avg r: 0.6383
08:26:53,873 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:28:23,792 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:29:53,645 root INFO Epoch 9 Global steps: 98000 Train loss: 0.1485
en_de Dev loss: 0.9060 r:0.1940
en_zh Dev loss: 0.7995 r:0.4733
ro_en Dev loss: 0.3694 r:0.8198
et_en Dev loss: 0.4923 r:0.6632
si_en Dev loss: 0.9147 r:0.5560
ne_en Dev loss: 0.5626 r:0.7284
ru_en Dev loss: 0.5163 r:0.7205
Current avg r:0.5936 Best avg r: 0.6383
08:34:21,993 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:35:51,916 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:37:21,767 root INFO Epoch 9 Global steps: 98700 Train loss: 0.1447
en_de Dev loss: 0.9182 r:0.1947
en_zh Dev loss: 0.7602 r:0.4880
ro_en Dev loss: 0.3352 r:0.8275
et_en Dev loss: 0.4816 r:0.6735
si_en Dev loss: 0.8542 r:0.5582
ne_en Dev loss: 0.5427 r:0.7197
ru_en Dev loss: 0.4525 r:0.7349
Current avg r:0.5995 Best avg r: 0.6383
08:41:50,269 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:43:20,19 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:44:49,701 root INFO Epoch 9 Global steps: 99400 Train loss: 0.1456
en_de Dev loss: 0.9344 r:0.1865
en_zh Dev loss: 0.7626 r:0.4888
ro_en Dev loss: 0.3367 r:0.8276
et_en Dev loss: 0.4847 r:0.6725
si_en Dev loss: 0.8193 r:0.5640
ne_en Dev loss: 0.5279 r:0.7229
ru_en Dev loss: 0.4591 r:0.7323
Current avg r:0.5992 Best avg r: 0.6383
08:49:18,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:50:48,146 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:52:18,4 root INFO Epoch 9 Global steps: 100100 Train loss: 0.1414
en_de Dev loss: 0.9069 r:0.1789
en_zh Dev loss: 0.7596 r:0.4788
ro_en Dev loss: 0.3346 r:0.8237
et_en Dev loss: 0.4668 r:0.6637
si_en Dev loss: 0.9518 r:0.5502
ne_en Dev loss: 0.5698 r:0.7187
ru_en Dev loss: 0.4940 r:0.7148
Current avg r:0.5898 Best avg r: 0.6383
08:56:46,461 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
08:58:16,198 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
08:59:45,932 root INFO Epoch 9 Global steps: 100800 Train loss: 0.1519
en_de Dev loss: 0.9147 r:0.1664
en_zh Dev loss: 0.7369 r:0.4825
ro_en Dev loss: 0.3230 r:0.8276
et_en Dev loss: 0.4891 r:0.6650
si_en Dev loss: 0.8208 r:0.5533
ne_en Dev loss: 0.5078 r:0.7144
ru_en Dev loss: 0.4338 r:0.7297
Current avg r:0.5913 Best avg r: 0.6383
09:04:14,409 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:05:44,148 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:07:13,802 root INFO Epoch 9 Global steps: 101500 Train loss: 0.1456
en_de Dev loss: 0.9354 r:0.1926
en_zh Dev loss: 0.7663 r:0.4961
ro_en Dev loss: 0.3555 r:0.8262
et_en Dev loss: 0.5033 r:0.6666
si_en Dev loss: 0.8483 r:0.5608
ne_en Dev loss: 0.5514 r:0.7212
ru_en Dev loss: 0.4380 r:0.7534
Current avg r:0.6024 Best avg r: 0.6383
09:11:42,253 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:13:12,171 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:14:42,12 root INFO Epoch 9 Global steps: 102200 Train loss: 0.1449
en_de Dev loss: 0.9285 r:0.1763
en_zh Dev loss: 0.7938 r:0.4866
ro_en Dev loss: 0.3457 r:0.8277
et_en Dev loss: 0.4833 r:0.6609
si_en Dev loss: 0.8822 r:0.5579
ne_en Dev loss: 0.5091 r:0.7212
ru_en Dev loss: 0.4473 r:0.7480
Current avg r:0.5969 Best avg r: 0.6383
09:19:10,509 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:20:40,437 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:22:10,293 root INFO Epoch 9 Global steps: 102900 Train loss: 0.1440
en_de Dev loss: 0.9069 r:0.1841
en_zh Dev loss: 0.7426 r:0.4914
ro_en Dev loss: 0.3308 r:0.8267
et_en Dev loss: 0.4868 r:0.6653
si_en Dev loss: 0.8167 r:0.5608
ne_en Dev loss: 0.5019 r:0.7189
ru_en Dev loss: 0.4378 r:0.7435
Current avg r:0.5987 Best avg r: 0.6383
09:26:38,757 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:28:08,681 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:29:38,541 root INFO Epoch 9 Global steps: 103600 Train loss: 0.1403
en_de Dev loss: 0.9164 r:0.1724
en_zh Dev loss: 0.7434 r:0.4950
ro_en Dev loss: 0.3184 r:0.8297
et_en Dev loss: 0.4877 r:0.6692
si_en Dev loss: 0.8188 r:0.5635
ne_en Dev loss: 0.5081 r:0.7130
ru_en Dev loss: 0.4341 r:0.7441
Current avg r:0.5981 Best avg r: 0.6383
09:34:07,4 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:35:36,839 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:37:06,706 root INFO Epoch 9 Global steps: 104300 Train loss: 0.1426
en_de Dev loss: 0.9412 r:0.1600
en_zh Dev loss: 0.8042 r:0.4788
ro_en Dev loss: 0.3562 r:0.8259
et_en Dev loss: 0.4919 r:0.6560
si_en Dev loss: 0.9362 r:0.5404
ne_en Dev loss: 0.5468 r:0.7157
ru_en Dev loss: 0.5133 r:0.7283
Current avg r:0.5865 Best avg r: 0.6383
09:41:35,210 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:43:05,158 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:44:35,25 root INFO Epoch 9 Global steps: 105000 Train loss: 0.1406
en_de Dev loss: 0.9264 r:0.1839
en_zh Dev loss: 0.7605 r:0.4906
ro_en Dev loss: 0.3314 r:0.8268
et_en Dev loss: 0.4884 r:0.6615
si_en Dev loss: 0.8689 r:0.5515
ne_en Dev loss: 0.5857 r:0.7205
ru_en Dev loss: 0.4633 r:0.7349
Current avg r:0.5957 Best avg r: 0.6383
09:49:04,755 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:50:34,628 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:52:04,413 root INFO Epoch 10 Global steps: 105700 Train loss: 0.1310
en_de Dev loss: 0.9336 r:0.1771
en_zh Dev loss: 0.7525 r:0.4936
ro_en Dev loss: 0.3503 r:0.8286
et_en Dev loss: 0.5118 r:0.6590
si_en Dev loss: 0.8644 r:0.5542
ne_en Dev loss: 0.5415 r:0.7190
ru_en Dev loss: 0.4648 r:0.7380
Current avg r:0.5956 Best avg r: 0.6383
09:56:32,635 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
09:58:02,552 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
09:59:32,371 root INFO Epoch 10 Global steps: 106400 Train loss: 0.1250
en_de Dev loss: 0.9338 r:0.1860
en_zh Dev loss: 0.7931 r:0.4942
ro_en Dev loss: 0.3617 r:0.8272
et_en Dev loss: 0.5082 r:0.6654
si_en Dev loss: 0.8613 r:0.5604
ne_en Dev loss: 0.5062 r:0.7223
ru_en Dev loss: 0.4764 r:0.7427
Current avg r:0.5997 Best avg r: 0.6383
10:04:00,932 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:05:30,710 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:07:00,408 root INFO Epoch 10 Global steps: 107100 Train loss: 0.1310
en_de Dev loss: 0.8983 r:0.1931
en_zh Dev loss: 0.7480 r:0.4881
ro_en Dev loss: 0.3330 r:0.8251
et_en Dev loss: 0.4934 r:0.6555
si_en Dev loss: 0.8802 r:0.5526
ne_en Dev loss: 0.5929 r:0.7187
ru_en Dev loss: 0.4935 r:0.7190
Current avg r:0.5932 Best avg r: 0.6383
10:11:29,8 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:12:58,788 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:14:28,436 root INFO Epoch 10 Global steps: 107800 Train loss: 0.1243
en_de Dev loss: 0.9094 r:0.1933
en_zh Dev loss: 0.7419 r:0.4889
ro_en Dev loss: 0.3176 r:0.8246
et_en Dev loss: 0.4786 r:0.6610
si_en Dev loss: 0.8640 r:0.5536
ne_en Dev loss: 0.5638 r:0.7213
ru_en Dev loss: 0.4345 r:0.7453
Current avg r:0.5983 Best avg r: 0.6383
10:18:56,989 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:20:26,769 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:21:56,447 root INFO Epoch 10 Global steps: 108500 Train loss: 0.1300
en_de Dev loss: 0.9172 r:0.1788
en_zh Dev loss: 0.7796 r:0.4807
ro_en Dev loss: 0.3227 r:0.8304
et_en Dev loss: 0.4661 r:0.6659
si_en Dev loss: 0.8567 r:0.5567
ne_en Dev loss: 0.5445 r:0.7252
ru_en Dev loss: 0.4625 r:0.7384
Current avg r:0.5966 Best avg r: 0.6383
10:26:25,76 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:27:54,864 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:29:24,623 root INFO Epoch 10 Global steps: 109200 Train loss: 0.1223
en_de Dev loss: 0.9155 r:0.1893
en_zh Dev loss: 0.7862 r:0.4777
ro_en Dev loss: 0.3358 r:0.8271
et_en Dev loss: 0.4939 r:0.6656
si_en Dev loss: 0.8860 r:0.5503
ne_en Dev loss: 0.5685 r:0.7167
ru_en Dev loss: 0.4457 r:0.7457
Current avg r:0.5961 Best avg r: 0.6383
10:33:53,251 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:35:23,22 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:36:52,715 root INFO Epoch 10 Global steps: 109900 Train loss: 0.1220
en_de Dev loss: 0.9133 r:0.1801
en_zh Dev loss: 0.7899 r:0.4759
ro_en Dev loss: 0.3501 r:0.8256
et_en Dev loss: 0.4664 r:0.6656
si_en Dev loss: 0.9153 r:0.5514
ne_en Dev loss: 0.5931 r:0.7233
ru_en Dev loss: 0.4996 r:0.7334
Current avg r:0.5936 Best avg r: 0.6383
10:41:21,302 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
10:42:51,274 root INFO 
Calculating results on dev set(s)... (lang agnostic mlp)
10:44:21,165 root INFO Epoch 10 Global steps: 110600 Train loss: 0.1237
en_de Dev loss: 0.9476 r:0.1706
en_zh Dev loss: 0.8031 r:0.4839
ro_en Dev loss: 0.3506 r:0.8255
et_en Dev loss: 0.4786 r:0.6690
si_en Dev loss: 0.9005 r:0.5554
ne_en Dev loss: 0.5682 r:0.7237
ru_en Dev loss: 0.4867 r:0.7377
Current avg r:0.5951 Best avg r: 0.6383
10:48:49,732 root INFO 
Calculating results on dev sets(s)... (lang specific MLP)
